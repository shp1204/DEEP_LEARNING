{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST 데이터로 다루는 여러가지 ML 기법\n",
    "1. BASIC\n",
    "\n",
    "2. epoch 활용\n",
    "\n",
    "3. Backpropagation\n",
    "\n",
    "4. softmax\n",
    "\n",
    "5. nn\n",
    "\n",
    "6. nn_xaiver\n",
    "\n",
    "7. nn_deep\n",
    "\n",
    "8. nn_dropout\n",
    "\n",
    "9. nn_batchnorm\n",
    "\n",
    "10. nn_selu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 7 Learning rate and Evaluation\n",
    "import torch\n",
    "import torchvision.datasets as dsets # mnist, imagenet 등의 데이터셋\n",
    "import torchvision.transforms as transforms # preprocessing 등이 있다\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# for reproducibility\n",
    "random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter\n",
    "batch_size = 100\n",
    "training_epochs = 100\n",
    "learning_rate = 0.5 # 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)\n",
    "\n",
    "# dataset loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "# pytorch에서는 crossentropyloss가 softmax를 자동으로 계산해준다\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)   \n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# BASIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = 0.331270188\n"
     ]
    }
   ],
   "source": [
    "avg_cost = 0\n",
    "total_batch = len(data_loader)\n",
    "for X, Y in data_loader:\n",
    "    # reshape input image into [batch_size by 784]\n",
    "    # label is not one-hot encoded\n",
    "    X = X.view(-1, 28 * 28).to(device)\n",
    "    Y = Y.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = linear(X)\n",
    "    cost = criterion(hypothesis, Y)\n",
    "    cost.backward() # gradient 계산\n",
    "    optimizer.step() # update\n",
    "\n",
    "    avg_cost += cost / total_batch\n",
    "print('cost =', '{:.9f}'.format(avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9075000286102295\n",
      "Label:  8\n",
      "Prediction:  3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the model using test sets\n",
    "# gradient 를 계산하지 않는다 !\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = linear(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())\n",
    "\n",
    "    # Get one and predict\n",
    "    r = random.randint(0, len(mnist_test) - 1)\n",
    "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
    "    Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
    "\n",
    "    print('Label: ', Y_single_data.item())\n",
    "    single_prediction = linear(X_single_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
    "\n",
    "    plt.imshow(mnist_test.test_data[r:r + 1].view(28, 28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# epoch 활용\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "60000장을 한 번에 학습시키지 않고 batch를 나눈다. 그 때 한 batch의 size를 batch size라고 한다.\n",
    "\n",
    "* 10000개 / 2 = 500\n",
    "* 2 : batch\n",
    "* 500 : size\n",
    "\n",
    "epoch : 1000개를 몇 번 학습할 것인가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.267898083\n",
      "Epoch: 0002 cost = 0.266977906\n",
      "Epoch: 0003 cost = 0.265936792\n",
      "Epoch: 0004 cost = 0.265145034\n",
      "Epoch: 0005 cost = 0.264419228\n",
      "Epoch: 0006 cost = 0.263605416\n",
      "Epoch: 0007 cost = 0.262877375\n",
      "Epoch: 0008 cost = 0.262141317\n",
      "Epoch: 0009 cost = 0.261658251\n",
      "Epoch: 0010 cost = 0.261049151\n",
      "Epoch: 0011 cost = 0.260444641\n",
      "Epoch: 0012 cost = 0.259924263\n",
      "Epoch: 0013 cost = 0.259457320\n",
      "Epoch: 0014 cost = 0.258699924\n",
      "Epoch: 0015 cost = 0.258245438\n",
      "Epoch: 0016 cost = 0.257845134\n",
      "Epoch: 0017 cost = 0.257392794\n",
      "Epoch: 0018 cost = 0.257036150\n",
      "Epoch: 0019 cost = 0.256442666\n",
      "Epoch: 0020 cost = 0.255988419\n",
      "Epoch: 0021 cost = 0.255522013\n",
      "Epoch: 0022 cost = 0.255438834\n",
      "Epoch: 0023 cost = 0.255002797\n",
      "Epoch: 0024 cost = 0.254428953\n",
      "Epoch: 0025 cost = 0.254283160\n",
      "Epoch: 0026 cost = 0.253764987\n",
      "Epoch: 0027 cost = 0.253715068\n",
      "Epoch: 0028 cost = 0.253079265\n",
      "Epoch: 0029 cost = 0.252972841\n",
      "Epoch: 0030 cost = 0.252389997\n",
      "Epoch: 0031 cost = 0.252211004\n",
      "Epoch: 0032 cost = 0.251875281\n",
      "Epoch: 0033 cost = 0.251680285\n",
      "Epoch: 0034 cost = 0.251466334\n",
      "Epoch: 0035 cost = 0.251090199\n",
      "Epoch: 0036 cost = 0.250829339\n",
      "Epoch: 0037 cost = 0.250768453\n",
      "Epoch: 0038 cost = 0.250362903\n",
      "Epoch: 0039 cost = 0.249953628\n",
      "Epoch: 0040 cost = 0.249873295\n",
      "Epoch: 0041 cost = 0.249620184\n",
      "Epoch: 0042 cost = 0.249231070\n",
      "Epoch: 0043 cost = 0.249124840\n",
      "Epoch: 0044 cost = 0.248847768\n",
      "Epoch: 0045 cost = 0.248554751\n",
      "Epoch: 0046 cost = 0.248528421\n",
      "Epoch: 0047 cost = 0.248285949\n",
      "Epoch: 0048 cost = 0.247966722\n",
      "Epoch: 0049 cost = 0.247809798\n",
      "Epoch: 0050 cost = 0.247565016\n",
      "Epoch: 0051 cost = 0.247309133\n",
      "Epoch: 0052 cost = 0.247275203\n",
      "Epoch: 0053 cost = 0.246985808\n",
      "Epoch: 0054 cost = 0.246787071\n",
      "Epoch: 0055 cost = 0.246571958\n",
      "Epoch: 0056 cost = 0.246412203\n",
      "Epoch: 0057 cost = 0.246414065\n",
      "Epoch: 0058 cost = 0.246147901\n",
      "Epoch: 0059 cost = 0.245842010\n",
      "Epoch: 0060 cost = 0.245706424\n",
      "Epoch: 0061 cost = 0.245700538\n",
      "Epoch: 0062 cost = 0.245320320\n",
      "Epoch: 0063 cost = 0.245294318\n",
      "Epoch: 0064 cost = 0.245016187\n",
      "Epoch: 0065 cost = 0.244959474\n",
      "Epoch: 0066 cost = 0.244550467\n",
      "Epoch: 0067 cost = 0.244696602\n",
      "Epoch: 0068 cost = 0.244467497\n",
      "Epoch: 0069 cost = 0.244301230\n",
      "Epoch: 0070 cost = 0.244173303\n",
      "Epoch: 0071 cost = 0.244091913\n",
      "Epoch: 0072 cost = 0.243837550\n",
      "Epoch: 0073 cost = 0.243620962\n",
      "Epoch: 0074 cost = 0.243600711\n",
      "Epoch: 0075 cost = 0.243450314\n",
      "Epoch: 0076 cost = 0.243341416\n",
      "Epoch: 0077 cost = 0.243308648\n",
      "Epoch: 0078 cost = 0.242958799\n",
      "Epoch: 0079 cost = 0.242934614\n",
      "Epoch: 0080 cost = 0.242924556\n",
      "Epoch: 0081 cost = 0.242636904\n",
      "Epoch: 0082 cost = 0.242392763\n",
      "Epoch: 0083 cost = 0.242305741\n",
      "Epoch: 0084 cost = 0.242304802\n",
      "Epoch: 0085 cost = 0.242116883\n",
      "Epoch: 0086 cost = 0.241982639\n",
      "Epoch: 0087 cost = 0.241802350\n",
      "Epoch: 0088 cost = 0.241727963\n",
      "Epoch: 0089 cost = 0.241665721\n",
      "Epoch: 0090 cost = 0.241603792\n",
      "Epoch: 0091 cost = 0.241454348\n",
      "Epoch: 0092 cost = 0.241371661\n",
      "Epoch: 0093 cost = 0.241230473\n",
      "Epoch: 0094 cost = 0.241074026\n",
      "Epoch: 0095 cost = 0.241018355\n",
      "Epoch: 0096 cost = 0.240928277\n",
      "Epoch: 0097 cost = 0.240872502\n",
      "Epoch: 0098 cost = 0.240811035\n",
      "Epoch: 0099 cost = 0.240638405\n",
      "Epoch: 0100 cost = 0.240405306\n",
      "Learning finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = len(data_loader)\n",
    "\n",
    "    for X, Y in data_loader:\n",
    "        \n",
    "        # reshape input image into [batch_size by 784]\n",
    "        # label is not one-hot encoded\n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = linear(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward() # gradient 계산\n",
    "        optimizer.step() # update\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8640000224113464\n",
      "Label:  7\n",
      "Prediction:  7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the model using test sets\n",
    "# gradient 를 계산하지 않는다 !\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = linear(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())\n",
    "\n",
    "    # Get one and predict\n",
    "    r = random.randint(0, len(mnist_test) - 1)\n",
    "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
    "    Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
    "\n",
    "    print('Label: ', Y_single_data.item())\n",
    "    single_prediction = linear(X_single_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
    "\n",
    "    plt.imshow(mnist_test.test_data[r:r + 1].view(28, 28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "w1 = torch.nn.Parameter(torch.Tensor(784, 30)).to(device) # 784 = 28 * 28 \n",
    "b1 = torch.nn.Parameter(torch.Tensor(30)).to(device)\n",
    "w2 = torch.nn.Parameter(torch.Tensor(30, 10)).to(device)\n",
    "b2 = torch.nn.Parameter(torch.Tensor(10)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.8375,  0.9892,  1.4047, -0.5649,  0.2165, -2.2377,  0.2952,  1.5709,\n",
       "        -0.1312, -1.0118], requires_grad=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.init.normal_(w1)\n",
    "torch.nn.init.normal_(b1)\n",
    "torch.nn.init.normal_(w2)\n",
    "torch.nn.init.normal_(b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    #  sigmoid function\n",
    "    return 1.0 / (1.0 + torch.exp(-x))\n",
    "    # return torch.div(torch.tensor(1), torch.add(torch.tensor(1.0), torch.exp(-x)))\n",
    "    \n",
    "def sigmoid_prime(x):\n",
    "    # derivative of the sigmoid function\n",
    "    return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "543\n",
      "537\n",
      "542\n",
      "538\n",
      "543\n",
      "539\n",
      "542\n",
      "539\n",
      "541\n",
      "542\n"
     ]
    }
   ],
   "source": [
    "X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)[:1000]\n",
    "Y_test = mnist_test.test_labels.to(device)[:1000]\n",
    "\n",
    "i = 0\n",
    "while not i == 10000:\n",
    "    for X, Y in data_loader:\n",
    "        i += 1\n",
    "\n",
    "        # forward\n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        Y = torch.zeros((batch_size, 10)).scatter_(1, Y.unsqueeze(1), 1).to(device)    # one-hot\n",
    "        \n",
    "        l1 = torch.add(torch.matmul(X, w1), b1)\n",
    "        a1 = sigmoid(l1)\n",
    "        \n",
    "        l2 = torch.add(torch.matmul(a1, w2), b2)\n",
    "        y_pred = sigmoid(l2)\n",
    "\n",
    "        diff = y_pred - Y\n",
    "\n",
    "        # Back prop (chain rule)\n",
    "        d_l2 = diff * sigmoid_prime(l2)\n",
    "        d_b2 = d_l2\n",
    "        d_w2 = torch.matmul(torch.transpose(a1, 0, 1), d_l2)\n",
    "\n",
    "        d_a1 = torch.matmul(d_l2, torch.transpose(w2, 0, 1))\n",
    "        d_l1 = d_a1 * sigmoid_prime(l1)\n",
    "        d_b1 = d_l1\n",
    "        d_w1 = torch.matmul(torch.transpose(X, 0, 1), d_l1)\n",
    "\n",
    "        w1 = w1 - learning_rate * d_w1\n",
    "        b1 = b1 - learning_rate * torch.mean(d_b1, 0)\n",
    "        \n",
    "        w2 = w2 - learning_rate * d_w2\n",
    "        b2 = b2 - learning_rate * torch.mean(d_b2, 0)\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            l1 = torch.add(torch.matmul(X_test, w1), b1)\n",
    "            a1 = sigmoid(l1)\n",
    "            l2 = torch.add(torch.matmul(a1, w2), b2)\n",
    "\n",
    "            y_pred = sigmoid(l2)\n",
    "            acct_mat = torch.argmax(y_pred, 1) == Y_test\n",
    "            acct_res = acct_mat.sum()\n",
    "            print(acct_res.item())\n",
    "\n",
    "        if i == 10000:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# MNIST data image of shape 28 * 28 = 784\n",
    "linear = torch.nn.Linear(784, 10, bias=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1492, -1.3618,  1.4942,  ..., -0.4333,  1.0782,  0.6280],\n",
       "        [ 0.6620, -0.1132, -0.1952,  ..., -0.9521, -1.0778,  0.8423],\n",
       "        [-1.2928, -0.6447, -0.1175,  ...,  0.3200, -1.9226, -0.4276],\n",
       "        ...,\n",
       "        [-0.4995, -0.8918, -0.1966,  ..., -1.4823, -0.8563,  0.8482],\n",
       "        [-0.2809,  1.0061, -0.3229,  ..., -0.0455, -0.7053,  1.5961],\n",
       "        [-2.0607,  0.4823, -0.8340,  ..., -1.1335,  0.8832,  1.2026]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialization\n",
    "torch.nn.init.normal_(linear.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)    # Softmax is internally computed.\n",
    "optimizer = torch.optim.Adam(linear.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 4.356550694\n",
      "Epoch: 0002 cost = 4.514595032\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-e3d81ee08ae0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mavg_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[1;31m# reshape input image into [batch_size by 784]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;31m# label is not one-hot encoded\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \"\"\"\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteStorage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetbands\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m     \u001b[1;31m# put it from HWC to CHW format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_batch = len(data_loader)\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for X, Y in data_loader:\n",
    "        # reshape input image into [batch_size by 784]\n",
    "        # label is not one-hot encoded\n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = linear(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Test the model using test sets\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = linear(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())\n",
    "\n",
    "    # Get one and predict\n",
    "    r = random.randint(0, len(mnist_test) - 1)\n",
    "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
    "    Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
    "\n",
    "    print('Label: ', Y_single_data.item())\n",
    "    single_prediction = linear(X_single_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# nn layers\n",
    "linear1 = torch.nn.Linear(784, 256, bias=True)\n",
    "linear2 = torch.nn.Linear(256, 256, bias=True)\n",
    "linear3 = torch.nn.Linear(256, 10, bias=True)\n",
    "relu = torch.nn.ReLU()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Initialization\n",
    "torch.nn.init.normal_(linear1.weight)\n",
    "torch.nn.init.normal_(linear2.weight)\n",
    "torch.nn.init.normal_(linear3.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# model\n",
    "model = torch.nn.Sequential(linear1, relu, linear2, relu, linear3).to(device)\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)    # Softmax is internally computed.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "total_batch = len(data_loader)\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for X, Y in data_loader:\n",
    "        # reshape input image into [batch_size by 784]\n",
    "        # label is not one-hot encoded\n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Test the model using test sets\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())\n",
    "\n",
    "    # Get one and predict\n",
    "    r = random.randint(0, len(mnist_test) - 1)\n",
    "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
    "    Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
    "\n",
    "    print('Label: ', Y_single_data.item())\n",
    "    single_prediction = model(X_single_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# nn_xaiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# nn layers\n",
    "linear1 = torch.nn.Linear(784, 256, bias=True)\n",
    "linear2 = torch.nn.Linear(256, 256, bias=True)\n",
    "linear3 = torch.nn.Linear(256, 10, bias=True)\n",
    "relu = torch.nn.ReLU()\n",
    "\n",
    "# xavier initialization\n",
    "torch.nn.init.xavier_uniform_(linear1.weight)\n",
    "torch.nn.init.xavier_uniform_(linear2.weight)\n",
    "torch.nn.init.xavier_uniform_(linear3.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# model\n",
    "model = torch.nn.Sequential(linear1, relu, linear2, relu, linear3).to(device)\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)    # Softmax is internally computed.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "total_batch = len(data_loader)\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for X, Y in data_loader:\n",
    "        # reshape input image into [batch_size by 784]\n",
    "        # label is not one-hot encoded\n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Test the model using test sets\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())\n",
    "\n",
    "    # Get one and predict\n",
    "    r = random.randint(0, len(mnist_test) - 1)\n",
    "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
    "    Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
    "\n",
    "    print('Label: ', Y_single_data.item())\n",
    "    single_prediction = model(X_single_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# nn_deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# xavier initialization\n",
    "torch.nn.init.xavier_uniform_(linear1.weight)\n",
    "torch.nn.init.xavier_uniform_(linear2.weight)\n",
    "torch.nn.init.xavier_uniform_(linear3.weight)\n",
    "torch.nn.init.xavier_uniform_(linear4.weight)\n",
    "torch.nn.init.xavier_uniform_(linear5.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# model\n",
    "model = torch.nn.Sequential(linear1, relu, linear2, relu, linear3).to(device)\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)    # Softmax is internally computed.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "total_batch = len(data_loader)\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for X, Y in data_loader:\n",
    "        # reshape input image into [batch_size by 784]\n",
    "        # label is not one-hot encoded\n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Test the model using test sets\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())\n",
    "\n",
    "    # Get one and predict\n",
    "    r = random.randint(0, len(mnist_test) - 1)\n",
    "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
    "    Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
    "\n",
    "    print('Label: ', Y_single_data.item())\n",
    "    single_prediction = model(X_single_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# nn_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# nn layers\n",
    "linear1 = torch.nn.Linear(784, 512, bias=True)\n",
    "linear2 = torch.nn.Linear(512, 512, bias=True)\n",
    "linear3 = torch.nn.Linear(512, 512, bias=True)\n",
    "linear4 = torch.nn.Linear(512, 512, bias=True)\n",
    "linear5 = torch.nn.Linear(512, 10, bias=True)\n",
    "relu = torch.nn.ReLU()\n",
    "dropout = torch.nn.Dropout(p=drop_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# xavier initialization\n",
    "torch.nn.init.xavier_uniform_(linear1.weight)\n",
    "torch.nn.init.xavier_uniform_(linear2.weight)\n",
    "torch.nn.init.xavier_uniform_(linear3.weight)\n",
    "torch.nn.init.xavier_uniform_(linear4.weight)\n",
    "torch.nn.init.xavier_uniform_(linear5.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# model\n",
    "model = torch.nn.Sequential(linear1, relu, dropout,\n",
    "                            linear2, relu, dropout,\n",
    "                            linear3, relu, dropout,\n",
    "                            linear4, relu, dropout,\n",
    "                            linear5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)    # Softmax is internally computed.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.train()    # set the model to train mode (dropout=True)\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for X, Y in data_loader:\n",
    "        # reshape input image into [batch_size by 784]\n",
    "        # label is not one-hot encoded\n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Test model and check accuracy\n",
    "with torch.no_grad():\n",
    "    model.eval()    # set the model to evaluation mode (dropout=False)\n",
    "\n",
    "    # Test the model using test sets\n",
    "    X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())\n",
    "\n",
    "    # Get one and predict\n",
    "    r = random.randint(0, len(mnist_test) - 1)\n",
    "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
    "    Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
    "\n",
    "    print('Label: ', Y_single_data.item())\n",
    "    single_prediction = model(X_single_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# nn_batchnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# nn layers\n",
    "linear1 = torch.nn.Linear(784, 32, bias=True)\n",
    "linear2 = torch.nn.Linear(32, 32, bias=True)\n",
    "linear3 = torch.nn.Linear(32, 10, bias=True)\n",
    "relu = torch.nn.ReLU()\n",
    "bn1 = torch.nn.BatchNorm1d(32)\n",
    "bn2 = torch.nn.BatchNorm1d(32)\n",
    "\n",
    "nn_linear1 = torch.nn.Linear(784, 32, bias=True)\n",
    "nn_linear2 = torch.nn.Linear(32, 32, bias=True)\n",
    "nn_linear3 = torch.nn.Linear(32, 10, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# model\n",
    "bn_model = torch.nn.Sequential(linear1, bn1, relu,\n",
    "                            linear2, bn2, relu,\n",
    "                            linear3).to(device)\n",
    "nn_model = torch.nn.Sequential(nn_linear1, relu,\n",
    "                               nn_linear2, relu,\n",
    "                               nn_linear3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)    # Softmax is internally computed.\n",
    "bn_optimizer = torch.optim.Adam(bn_model.parameters(), lr=learning_rate)\n",
    "nn_optimizer = torch.optim.Adam(nn_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Save Losses and Accuracies every epoch\n",
    "# We are going to plot them later\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "\n",
    "valid_losses = []\n",
    "valid_accs = []\n",
    "\n",
    "train_total_batch = len(train_loader)\n",
    "test_total_batch = len(test_loader)\n",
    "for epoch in range(training_epochs):\n",
    "    bn_model.train()  # set the model to train mode\n",
    "\n",
    "    for X, Y in train_loader:\n",
    "        # reshape input image into [batch_size by 784]\n",
    "        # label is not one-hot encoded\n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        bn_optimizer.zero_grad()\n",
    "        bn_prediction = bn_model(X)\n",
    "        bn_loss = criterion(bn_prediction, Y)\n",
    "        bn_loss.backward()\n",
    "        bn_optimizer.step()\n",
    "\n",
    "        nn_optimizer.zero_grad()\n",
    "        nn_prediction = nn_model(X)\n",
    "        nn_loss = criterion(nn_prediction, Y)\n",
    "        nn_loss.backward()\n",
    "        nn_optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        bn_model.eval()     # set the model to evaluation mode\n",
    "\n",
    "        # Test the model using train sets\n",
    "        bn_loss, nn_loss, bn_acc, nn_acc = 0, 0, 0, 0\n",
    "        for i, (X, Y) in enumerate(train_loader):\n",
    "            X = X.view(-1, 28 * 28).to(device)\n",
    "            Y = Y.to(device)\n",
    "\n",
    "            bn_prediction = bn_model(X)\n",
    "            bn_correct_prediction = torch.argmax(bn_prediction, 1) == Y\n",
    "            bn_loss += criterion(bn_prediction, Y)\n",
    "            bn_acc += bn_correct_prediction.float().mean()\n",
    "\n",
    "            nn_prediction = nn_model(X)\n",
    "            nn_correct_prediction = torch.argmax(nn_prediction, 1) == Y\n",
    "            nn_loss += criterion(nn_prediction, Y)\n",
    "            nn_acc += nn_correct_prediction.float().mean()\n",
    "\n",
    "        bn_loss, nn_loss, bn_acc, nn_acc = bn_loss / train_total_batch, nn_loss / train_total_batch, bn_acc / train_total_batch, nn_acc / train_total_batch\n",
    "\n",
    "        # Save train losses/acc\n",
    "        train_losses.append([bn_loss, nn_loss])\n",
    "        train_accs.append([bn_acc, nn_acc])\n",
    "        print(\n",
    "            '[Epoch %d-TRAIN] Batchnorm Loss(Acc): bn_loss:%.5f(bn_acc:%.2f) vs No Batchnorm Loss(Acc): nn_loss:%.5f(nn_acc:%.2f)' % (\n",
    "            (epoch + 1), bn_loss.item(), bn_acc.item(), nn_loss.item(), nn_acc.item()))\n",
    "        # Test the model using test sets\n",
    "        bn_loss, nn_loss, bn_acc, nn_acc = 0, 0, 0, 0\n",
    "        for i, (X, Y) in enumerate(test_loader):\n",
    "            X = X.view(-1, 28 * 28).to(device)\n",
    "            Y = Y.to(device)\n",
    "\n",
    "            bn_prediction = bn_model(X)\n",
    "            bn_correct_prediction = torch.argmax(bn_prediction, 1) == Y\n",
    "            bn_loss += criterion(bn_prediction, Y)\n",
    "            bn_acc += bn_correct_prediction.float().mean()\n",
    "\n",
    "            nn_prediction = nn_model(X)\n",
    "            nn_correct_prediction = torch.argmax(nn_prediction, 1) == Y\n",
    "            nn_loss += criterion(nn_prediction, Y)\n",
    "            nn_acc += nn_correct_prediction.float().mean()\n",
    "\n",
    "        bn_loss, nn_loss, bn_acc, nn_acc = bn_loss / test_total_batch, nn_loss / test_total_batch, bn_acc / test_total_batch, nn_acc / test_total_batch\n",
    "\n",
    "        # Save valid losses/acc\n",
    "        valid_losses.append([bn_loss, nn_loss])\n",
    "        valid_accs.append([bn_acc, nn_acc])\n",
    "        print(\n",
    "            '[Epoch %d-VALID] Batchnorm Loss(Acc): bn_loss:%.5f(bn_acc:%.2f) vs No Batchnorm Loss(Acc): nn_loss:%.5f(nn_acc:%.2f)' % (\n",
    "                (epoch + 1), bn_loss.item(), bn_acc.item(), nn_loss.item(), nn_acc.item()))\n",
    "        print()\n",
    "\n",
    "print('Learning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_compare(loss_list: list, ylim=None, title=None) -> None:\n",
    "    bn = [i[0] for i in loss_list]\n",
    "    nn = [i[1] for i in loss_list]\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.plot(bn, label='With BN')\n",
    "    plt.plot(nn, label='Without BN')\n",
    "    if ylim:\n",
    "        plt.ylim(ylim)\n",
    "\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid('on')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_compare(train_losses, title='Training Loss at Epoch')\n",
    "plot_compare(train_accs, [0, 1.0], title='Training Acc at Epoch')\n",
    "plot_compare(valid_losses, title='Validation Loss at Epoch')\n",
    "plot_compare(valid_accs, [0, 1.0], title='Validation Acc at Epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nn_selu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.091px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
