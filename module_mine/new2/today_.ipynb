{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acsr   (0, 0)\t1\n",
      "  (0, 1)\t2\n",
      "  (1, 2)\t3\n",
      "  (2, 0)\t4\n",
      "  (2, 2)\t5\n",
      "Acoo   (0, 0)\t1\n",
      "  (0, 1)\t2\n",
      "  (1, 2)\t3\n",
      "  (2, 0)\t4\n",
      "  (2, 2)\t5\n",
      "[0, 0, 1, 2, 2]\n",
      "[0, 1, 2, 0, 2]\n",
      "[[0, 0, 1, 2, 2], [0, 1, 2, 0, 2]]\n",
      "[1 2 3 4 5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<3x3 sparse matrix of type '<class 'numpy.intc'>'\n",
       "\twith 5 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import torch\n",
    "\n",
    "__author__ = 'Andrea Esuli'\n",
    "\n",
    "Acsr = csr_matrix([[1, 2, 0], [0, 0, 3], [4, 0, 5]])\n",
    "print('Acsr',Acsr)\n",
    "\n",
    "Acoo = Acsr.tocoo()\n",
    "print('Acoo',Acoo)\n",
    "\n",
    "Apt = torch.sparse.LongTensor(torch.LongTensor([Acoo.row.tolist(), Acoo.col.tolist()]),\n",
    "                              torch.LongTensor(Acoo.data.astype(np.int32)))\n",
    "\n",
    "print(Acoo.row.tolist())\n",
    "print(Acoo.col.tolist())\n",
    "print([Acoo.row.tolist(), Acoo.col.tolist()])\n",
    "print(Acoo.data)\n",
    "\n",
    "Apt\n",
    "Acoo.data.astype\n",
    "Acsr.tocoo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def __init__(self, AF, labels, weight_channel):\n",
    "        super(mymodule, self).__init__()\n",
    "        self.AF = AF\n",
    "        self.labels = labels\n",
    "\n",
    "        # weight 크기 설정에 따라 node_feature 가 업데이트 될 수 있게\n",
    "        self.weight_channel = weight_channel\n",
    "\n",
    "        # csr_matrix to tensor\n",
    "        self.temp1 = self.AF.tocoo()\n",
    "        self.temp2 = torch.sparse.Tensor([self.temp1.row.tolist(),\n",
    "                                        self.temp1.col.tolist()])\n",
    "\n",
    "        self.weight = Parameter(torch.Tensor(np.random.rand(self.AF.size,\n",
    "                                                            self.weight_channel)))\n",
    "        self.bias = Parameter(torch.Tensor(np.random.rand(self.weight_channel,\n",
    "                                                          1)))\n",
    "\n",
    "        self.bias = self.bias.unsqueeze(1)\n",
    "\n",
    "        # AF X Weight + bias\n",
    "        self.cal = torch.matmul(self.temp2, self.weight)\n",
    "        self.cal2 = torch.add(self.cal, self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네트워크 초기화\n",
    "# custom weights initialization called on netG and netD\n",
    "b\n",
    "def weights_init(m) :\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1 :\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1 :\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            \n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # kaiming_normalizaion : 어떤 \n",
    "                nn.init.kaiming_normal_(m.weight, \n",
    "                                        mode='fan_out', \n",
    "                                        nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "                    \n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                \n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myreg(W, Y): # features, labels\n",
    "    from numpy.linalg import pinv\n",
    "    m, n = Y.shape # features, labels\n",
    "    k = W.shape[1] # 열 개수\n",
    "    print('k : {}'.format(k))\n",
    "    X = pinv(W.T.dot(W)).dot(W.T).dot(Y)\n",
    "    Y_hat = W.dot(X)\n",
    "    Residuals = Y_hat - Y # 잔차 계산\n",
    "    MSE = np.square(Residuals).sum(axis=0) / (m - 2)\n",
    "    X_var = (MSE[:, None] * pinv(W.T.dot(W)).flatten()).reshape(n, k, k)\n",
    "    Tstat = X / np.sqrt(X_var.diagonal(axis1=1, axis2=2)).T\n",
    "    return X, Tstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k : 5\n"
     ]
    }
   ],
   "source": [
    "W = np.array([\n",
    "        [ 1, -1,  0,  0,  1],\n",
    "        [ 0, -1,  1,  0,  0],\n",
    "        [ 1,  0,  0,  1,  0],\n",
    "        [ 0,  1, -1,  0,  1],\n",
    "        [ 1, -1,  0,  0, -1],\n",
    "    ])\n",
    "\n",
    "Y = np.array([2, 4, 1, 5, 3])[:, None]\n",
    "\n",
    "X, V = myreg(W, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 1"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# data\n",
    "#노드 연결 정보\n",
    "edges = np.array([[0 ,1],[2 ,3],[1 ,4],[3 ,4],[4 ,5],[4 ,6]])\n",
    "# 각 노드 특성 정보(H) = 7 X 4\n",
    "features = sp.csr_matrix([[1, 0, 0, 0],[0, 1, 0, 0],[1, 0, 0, 0],[0, 1, 0, 0],[0, 0, 1, 0],[0, 0, 0, 1],[0, 0, 0, 1]])\n",
    "# edge 특성 정보\n",
    "edge_features = [[3],[5],[1],[10],[6],[8]]\n",
    "# labels \n",
    "labels = np.array([1,4,5,2,6,3,0])\n",
    "\n",
    "# 단위 행렬 더해주기\n",
    "# direction matrix 생성\n",
    "adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:,0], edges[:,1])),\n",
    "             shape = (labels.shape[0], labels.shape[0]),\n",
    "             dtype = np.float32)\n",
    "adj = adj + sp.eye(adj.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# normalize\n",
    "def normalize(mx) :\n",
    "    rowsum = np.array(mx.sum(1)) # 각 노드 정보 개수\n",
    "    print('=====row별 feature 특성 합=====')\n",
    "    #print(rowsum)\n",
    "\n",
    "    # r_inv\n",
    "    # 역행렬로 np.power 수행\n",
    "    r_inv = np.power(rowsum, 0).flatten() # 0, 1, # power : 0, 1, 8, 27, ,,, / 0, 1, 4, 9, ,,, / 0, 1, 0.5, 0.333, 0.25\n",
    "    print('===== 역행렬로 np.power 수행 =====')\n",
    "    r_inv[np.isinf(r_inv)] = 0 \n",
    "    #print(r_inv)\n",
    "    \n",
    "    # r_mat_inv\n",
    "    r_mat_inv = sp.diags(r_inv) # 행렬로 만들어줌\n",
    "    #print(r_mat_inv.toarray())\n",
    "    \n",
    "    # 노드 adj 와 노드 feature 정보 행렬연산\n",
    "    print('=====adj, feature 행렬곱=====') \n",
    "    mx = r_mat_inv.dot(mx) \n",
    "\n",
    "    print(mx.toarray())\n",
    "    return mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====row별 feature 특성 합=====\n",
      "===== 역행렬로 np.power 수행 =====\n",
      "=====adj, feature 행렬곱=====\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]]\n",
      "=====row별 feature 특성 합=====\n",
      "===== 역행렬로 np.power 수행 =====\n",
      "=====adj, feature 행렬곱=====\n",
      "[[1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]]\n",
      "======1번째======\n",
      "[[1. 1. 0. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [1. 1. 0. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 2.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]]\n",
      "======2번째======\n",
      "[[1. 2. 1. 0.]\n",
      " [0. 1. 2. 2.]\n",
      " [1. 2. 1. 0.]\n",
      " [0. 1. 2. 2.]\n",
      " [0. 0. 1. 4.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "features = normalize(features)\n",
    "adj = normalize(adj) # 대각행렬\n",
    "\n",
    "# 행렬곱을 위한 array \n",
    "adj_arr = adj.toarray()\n",
    "features_arr = features.toarray()\n",
    "\n",
    "# hop 에 따라 정보 전달\n",
    "hop = 2\n",
    "for idx in range(hop) :\n",
    "    features_arr = np.matmul(adj_arr, features_arr) # 여기에 weight 곱하기, bias 더하기\n",
    "    print('======{0}번째======'.format(idx+1))\n",
    "    print('{}'.format(features_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 4, 5, 2, 6, 3, 0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[0, 0, 1, 2, 2, 3, 1, 3, 4, 4, 5, 4, 6],\n",
       "                       [0, 1, 1, 2, 3, 3, 4, 4, 4, 5, 5, 6, 6]]),\n",
       "       values=tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       "       size=(7, 7), nnz=13, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_train = range(5)\n",
    "features = torch.FloatTensor(np.array(features_arr)) # .todense()\n",
    "labels = torch.LongTensor(labels) # 원핫인코딩 된 label 중 해당하는 label이 몇 번 째인지\n",
    "print(labels)\n",
    "\n",
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "\n",
    "    # 노드\n",
    "    indices = torch.from_numpy(\n",
    "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64)) # vstack : 행 추가\n",
    "    # 노드 간 edge의 정보\n",
    "    values = torch.from_numpy(sparse_mx.data) # numpy.ndarray를 tensor로 올려줌\n",
    "    # 노드 개수, 특성 개수\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "\n",
    "    return torch.sparse.FloatTensor(indices, values, shape) # sparse : 크기에 맞게 값을 뿌려주는 것 같은데 규칙 잘 모르겠다\n",
    "\n",
    "t = sparse_mx_to_torch_sparse_tensor(adj)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## 확인\n",
    "# print('===단위행렬 더하기 전===')\n",
    "# print('{}'.format(adj))\n",
    "# print(adj.toarray())\n",
    "# print()\n",
    "\n",
    "## 고려할 것 : 단위행렬(자기자신의 정보) 전달\n",
    "#adj = adj + sp.eye(adj.shape[0])\n",
    "#print('===단위행렬 더한 후===')\n",
    "#print('{}'.format(adj))\n",
    "#print(adj.toarray())\n",
    "\n",
    "# num_nodes = max + 1 = 7\n",
    "# num_edges = len(edges) = 6\n",
    "\n",
    "# edge정보를 어떻게 맞춰줄것인가_dimension\n",
    "\n",
    "# feature 정보 학습, label regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Input 값 확인 =============\n",
      "AF.size : 13\n",
      "weight_channel : 2\n",
      "==================csr_matrix to tensor==============================\n",
      "temp1.row : 13\n",
      "temp1.col : 13\n",
      "temp2.size : torch.Size([2, 13])\n",
      "======================weight, bias 설정==============================\n",
      "Parameter containing:\n",
      "tensor([[0.3452],\n",
      "        [0.4532]], requires_grad=True)\n",
      "tensor([[[0.3452]],\n",
      "\n",
      "        [[0.4532]]], grad_fn=<UnsqueezeBackward0>)\n",
      "========================= calculate ======================\n",
      "tensor([[21.5024, 21.1556],\n",
      "        [25.1407, 25.2825]], grad_fn=<MmBackward>)\n",
      "tensor([[[21.8476, 21.5007],\n",
      "         [25.4859, 25.6276]],\n",
      "\n",
      "        [[21.9556, 21.6088],\n",
      "         [25.5939, 25.7356]]], grad_fn=<AddBackward0>)\n",
      "========================= process =========================\n",
      "  (0, 1)\t1.0\n",
      "  (0, 0)\t1.0\n",
      "  (1, 4)\t1.0\n",
      "  (1, 1)\t1.0\n",
      "  (2, 3)\t1.0\n",
      "  (2, 2)\t1.0\n",
      "  (3, 4)\t1.0\n",
      "  (3, 3)\t1.0\n",
      "  (4, 6)\t1.0\n",
      "  (4, 5)\t1.0\n",
      "  (4, 4)\t1.0\n",
      "  (5, 5)\t1.0\n",
      "  (6, 6)\t1.0 x Parameter containing:\n",
      "tensor([[0.0915, 0.8440],\n",
      "        [0.4047, 0.7411],\n",
      "        [0.0210, 0.0736],\n",
      "        [0.8225, 0.6714],\n",
      "        [0.3020, 0.4605],\n",
      "        [0.2851, 0.9103],\n",
      "        [0.9645, 0.5874],\n",
      "        [0.8574, 0.8603],\n",
      "        [0.9212, 0.7298],\n",
      "        [0.3748, 0.5547],\n",
      "        [0.8893, 0.2937],\n",
      "        [0.5085, 0.9291],\n",
      "        [0.4558, 0.3946]], requires_grad=True) = tensor([[21.5024, 21.1556],\n",
      "        [25.1407, 25.2825]], grad_fn=<MmBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<today_third.mymodule at 0x1824a94e670>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from today_third import mymodule\n",
    "mymodule(adj, labels, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init 시작\n",
      "  (0, 1)\t1.0\n",
      "  (0, 0)\t1.0\n",
      "  (1, 4)\t1.0\n",
      "  (1, 1)\t1.0\n",
      "  (2, 3)\t1.0\n",
      "  (2, 2)\t1.0\n",
      "  (3, 4)\t1.0\n",
      "  (3, 3)\t1.0\n",
      "  (4, 6)\t1.0\n",
      "  (4, 5)\t1.0\n",
      "  (4, 4)\t1.0\n",
      "  (5, 5)\t1.0\n",
      "  (6, 6)\t1.0\n",
      "[0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 4, 5, 6]\n",
      "[1, 0, 4, 1, 3, 2, 4, 3, 6, 5, 4, 5, 6]\n",
      "weight : Parameter containing:\n",
      "tensor([[ 0.2727,  0.5237],\n",
      "        [-0.2759, -0.3060],\n",
      "        [ 0.1658,  0.1266],\n",
      "        [ 0.5454, -0.3601],\n",
      "        [ 0.1306,  0.2945],\n",
      "        [-0.3975,  0.0127],\n",
      "        [ 0.3219, -0.2677],\n",
      "        [ 0.0980, -0.5871],\n",
      "        [-0.5026, -0.2000],\n",
      "        [-0.0759,  0.1696],\n",
      "        [ 0.1548,  0.1688],\n",
      "        [ 0.4528, -0.4336],\n",
      "        [ 0.3609, -0.4481]], requires_grad=True), bias : Parameter containing:\n",
      "tensor([[-0.2329],\n",
      "        [-0.5525]], requires_grad=True)\n",
      "1end\n",
      "forward 시작\n",
      "2end\n",
      "tensor([[3.9386, 0.0000],\n",
      "        [3.7605, 0.0000]], grad_fn=<ReluBackward0>)\n",
      "init 시작\n",
      "  (0, 1)\t1.0\n",
      "  (0, 0)\t1.0\n",
      "  (1, 4)\t1.0\n",
      "  (1, 1)\t1.0\n",
      "  (2, 3)\t1.0\n",
      "  (2, 2)\t1.0\n",
      "  (3, 4)\t1.0\n",
      "  (3, 3)\t1.0\n",
      "  (4, 6)\t1.0\n",
      "  (4, 5)\t1.0\n",
      "  (4, 4)\t1.0\n",
      "  (5, 5)\t1.0\n",
      "  (6, 6)\t1.0\n",
      "[0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 4, 5, 6]\n",
      "[1, 0, 4, 1, 3, 2, 4, 3, 6, 5, 4, 5, 6]\n",
      "weight : Parameter containing:\n",
      "tensor([[-0.5842,  0.1018],\n",
      "        [-0.3682, -0.1311],\n",
      "        [-0.1863,  0.0650],\n",
      "        [-0.2503,  0.3852],\n",
      "        [ 0.5479, -0.2592],\n",
      "        [ 0.1242,  0.1405],\n",
      "        [-0.3106, -0.5472],\n",
      "        [-0.3974, -0.3188],\n",
      "        [ 0.2443,  0.2853],\n",
      "        [ 0.2333, -0.3627],\n",
      "        [ 0.3568, -0.6157],\n",
      "        [-0.2222,  0.5157],\n",
      "        [ 0.4520, -0.3817]], requires_grad=True), bias : Parameter containing:\n",
      "tensor([[-1.3388],\n",
      "        [ 1.1748]], requires_grad=True)\n",
      "1end\n",
      "forward 시작\n",
      "2end\n",
      "tensor([[2.3835, 0.0000],\n",
      "        [4.7129, 0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from today_fourth import *\n",
    "\n",
    "for epoch in range(2) :\n",
    "    a = mymodel(adj, labels, 2)\n",
    "    print(a.forward())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# data\n",
    "#노드 연결 정보\n",
    "edges = np.array([[0 ,1],[2 ,3],[1 ,4],[3 ,4],[4 ,5],[4 ,6]])\n",
    "# 각 노드 특성 정보(H) = 7 X 4\n",
    "features = sp.csr_matrix([[1, 0, 0, 0],[0, 1, 0, 0],[1, 0, 0, 0],[0, 1, 0, 0],[0, 0, 1, 0],[0, 0, 0, 1],[0, 0, 0, 1]])\n",
    "# edge 특성 정보\n",
    "edge_features = [[3],[5],[1],[10],[6],[8]]\n",
    "# labels \n",
    "labels = np.array([1,4,5,2,6,3,0])\n",
    "\n",
    "# 단위 행렬 더해주기\n",
    "# direction matrix 생성\n",
    "adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:,0], edges[:,1])),\n",
    "             shape = (labels.shape[0], labels.shape[0]),\n",
    "             dtype = np.float32)\n",
    "adj = adj + sp.eye(adj.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0., 0.],\n",
       "       [0., 1., 1., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [0., 1., 1., 0.],\n",
       "       [0., 0., 1., 2.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(adj.toarray(), features.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====row별 feature 특성 합=====\n",
      "===== 역행렬로 np.power 수행 =====\n",
      "=====adj, feature 행렬곱=====\n",
      "[[1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]]\n",
      "  (0, 0)\t1.0\n",
      "  (0, 1)\t1.0\n",
      "  (1, 1)\t1.0\n",
      "  (1, 4)\t1.0\n",
      "  (2, 2)\t1.0\n",
      "  (2, 3)\t1.0\n",
      "  (3, 3)\t1.0\n",
      "  (3, 4)\t1.0\n",
      "  (4, 4)\t1.0\n",
      "  (4, 5)\t1.0\n",
      "  (4, 6)\t1.0\n",
      "  (5, 5)\t1.0\n",
      "  (6, 6)\t1.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.FloatTensor(normalize(adj).toarray())\n",
    "\n",
    "\n",
    "print(adj.tocoo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# features, adj 생으로 그냥 들어가면\n",
    "\n",
    "# 1. normalize -> tensor에 올림\n",
    "#    labels -> tensor에 올림\n",
    "\n",
    "# 2. A,F  matmul\n",
    "\n",
    "# 3. F1 = AF * W ( convolution1 _ weight_channel1 )\n",
    "\n",
    "# 4. F2 = AF1 * W ( convolution2 _ weight_channel2 ) : W.shape = (weight_channel1 X wight_channel2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================init 시작=====================\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'toarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-0fe5230d8df8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtoday_fifth\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmymodel5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_channel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\연구\\module_mine\\new2\\today_fifth.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, A, F, labels, weight_channel)\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'=================init 시작====================='\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;31m#self.A = torch.FloatTensor(normalize(A).toarray())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[1;31m#self.F = torch.FloatTensor(normalize(F).toarray())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'toarray'"
     ]
    }
   ],
   "source": [
    "from today_fifth import *\n",
    "\n",
    "mymodel5(adj, features, labels, weight_channel=(5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===단위행렬 더하기 전===\n",
      "  (0, 1)\t1.0\n",
      "  (2, 3)\t1.0\n",
      "  (1, 4)\t1.0\n",
      "  (3, 4)\t1.0\n",
      "  (4, 5)\t1.0\n",
      "  (4, 6)\t1.0\n",
      "[[0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "======1번째======\n",
      "[[0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 2.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "======2번째======\n",
      "[[0. 0. 1. 0.]\n",
      " [0. 0. 0. 2.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 2.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "=====adj, feature 행렬곱=====\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]]\n",
      "=====adj, feature 행렬곱=====\n",
      "[[1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]]\n",
      "tensor([1, 4, 5, 2, 6, 3, 0])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "#노드 연결 정보\n",
    "edges = np.array([[0 ,1], [2 ,3], [1 ,4], [3 ,4],[4 ,5],[4 ,6]])\n",
    "\n",
    "# 각 노드 특성 정보(H) = 7 X 4\n",
    "features = sp.csr_matrix([[1, 0, 0, 0],\n",
    "                          [0, 1, 0, 0],\n",
    "                          [1, 0, 0, 0],\n",
    "                          [0, 1, 0, 0],\n",
    "                          [0, 0, 1, 0],\n",
    "                          [0, 0, 0, 1],\n",
    "                          [0, 0, 0, 1]])\n",
    "\n",
    "# edge 특성 정보\n",
    "edge_features = [[3],[5], [1],[10], [6],[8]]\n",
    "\n",
    "# labels \n",
    "labels = np.array([1, 4, 5, 2, 6,3,0])\n",
    "\n",
    "# 단위 행렬 더해주기\n",
    "# direction matrix 생성\n",
    "adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:,0], edges[:,1])),\n",
    "             shape = (labels.shape[0], labels.shape[0]),\n",
    "             dtype = np.float32)\n",
    "## 확인\n",
    "print('===단위행렬 더하기 전===')\n",
    "print('{}'.format(adj))\n",
    "print(adj.toarray())\n",
    "print()\n",
    "\n",
    "## 고려할 것 : 단위행렬(자기자신의 정보) 전달\n",
    "#adj = adj + sp.eye(adj.shape[0])\n",
    "#print('===단위행렬 더한 후===')\n",
    "#print('{}'.format(adj))\n",
    "#print(adj.toarray())\n",
    "def normalize(mx) :\n",
    "    rowsum = np.array(mx.sum(1)) # 각 노드 정보 개수\n",
    "    #print('=====row별 feature 특성 합=====')\n",
    "    #print(rowsum)\n",
    "    \n",
    "    # r_inv\n",
    "    # 역행렬로 np.power 수행\n",
    "    r_inv = np.power(rowsum, 0).flatten() # 0, 1, # power : 0, 1, 8, 27, ,,, / 0, 1, 4, 9, ,,, / 0, 1, 0.5, 0.333, 0.25\n",
    "    #print('===== 역행렬로 np.power 수행 =====')\n",
    "    r_inv[np.isinf(r_inv)] = 0 \n",
    "    #print(r_inv)\n",
    "\n",
    "    # r_mat_inv\n",
    "    r_mat_inv = sp.diags(r_inv) # 행렬로 만들어줌\n",
    "    #print(r_mat_inv.toarray())\n",
    "    \n",
    "    # 노드 adj 와 노드 feature 정보 행렬연산\n",
    "    print('=====adj, feature 행렬곱=====')\n",
    "    mx = r_mat_inv.dot(mx) \n",
    "    print(mx.toarray())\n",
    "    return mx\n",
    "\n",
    "# num_nodes = max + 1 = 7\n",
    "# num_edges = len(edges) = 6\n",
    "\n",
    "num_nodes = 7\n",
    "num_edges = len(edges)\n",
    "\n",
    "# direction matrix 생성\n",
    "adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\n",
    "                    shape=(labels.shape[0], labels.shape[0]),\n",
    "                    dtype=np.float32)\n",
    "\n",
    "## 고려할 것 : 단위행렬(자기자신의 정보) 전달\n",
    "# adj = adj + sp.eye(adj.shape[0])\n",
    "# print('===단위행렬 더한 후===')\n",
    "# print(adj.toarray())\n",
    "\n",
    "# edge정보를 어떻게 맞춰줄것인가_dimension\n",
    "\n",
    "# 행렬곱을 위한 array \n",
    "adj_arr = adj.toarray()\n",
    "features_arr = features.toarray()\n",
    "\n",
    "# hop 에 따라 정보 전달\n",
    "hop = 2\n",
    "for idx in range(hop) :\n",
    "    features_arr = np.matmul(adj_arr, features_arr) # 여기에 weight 곱하기, bias 더하기\n",
    "    print('======{0}번째======'.format(idx+1))\n",
    "    print('{}'.format(features_arr))\n",
    "    \n",
    "    \n",
    "# feature 정보 학습, label regression\n",
    "\n",
    "\n",
    "# features : 현재 노드 + 연결된 노드 정보\n",
    "features = normalize(features)\n",
    "\n",
    "adj = normalize(adj + sp.eye(adj.shape[0])) # 대각행렬\n",
    "\n",
    "idx_train = range(5)\n",
    "features = torch.FloatTensor(np.array(features.todense()))\n",
    "labels = torch.LongTensor(labels) # 원핫인코딩 된 label 중 해당하는 label이 몇 번 째인지\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[0, 0, 1, 2, 2, 3, 1, 3, 4, 4, 5, 4, 6],\n",
       "                       [0, 1, 1, 2, 3, 3, 4, 4, 4, 5, 5, 6, 6]]),\n",
       "       values=tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       "       size=(7, 7), nnz=13, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "\n",
    "    # 노드\n",
    "    indices = torch.from_numpy(\n",
    "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64)) # vstack : 행 추가\n",
    "\n",
    "    # 노드 간 edge의 정보\n",
    "    values = torch.from_numpy(sparse_mx.data) # numpy.ndarray를 tensor로 올려줌\n",
    "\n",
    "    # 노드 개수, 특성 개수\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "\n",
    "    return torch.sparse.FloatTensor(indices, values, shape) # sparse : 크기에 맞게 값을 뿌려주는 것 같은데 규칙 잘 모르겠다.\n",
    "\n",
    "adj = sparse_mx_to_torch_sparse_tensor(adj)\n",
    "adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
