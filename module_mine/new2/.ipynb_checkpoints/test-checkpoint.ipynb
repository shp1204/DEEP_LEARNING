{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# graphsage 원본"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import graphsage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAGEConv(10, 4)\n"
     ]
    }
   ],
   "source": [
    "t = graphsage.SAGEConv(10, 4)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# make_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 더하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_game\n",
      "do_sum : 1 + 2 = 3\n",
      "temp_sum : 1 + 2 = 3\n",
      "check : True\n",
      "end_game\n"
     ]
    }
   ],
   "source": [
    "from make_test import my_class\n",
    "p = my_class(1, 2)\n",
    "p.check_sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------1번째-----------\n",
      "start_game\n",
      "do_sum : 1 + 2 = 3\n",
      "temp_sum : 1 + 2 = 3\n",
      "check : True\n",
      "end_game\n",
      "---------------2번째-----------\n",
      "start_game\n",
      "do_sum : 3 + -1 = 2\n",
      "temp_sum : 3 + -1 = 2\n",
      "check : True\n",
      "end_game\n",
      "---------------3번째-----------\n",
      "start_game\n",
      "do_sum : 100 + 20 = 120\n",
      "temp_sum : 100 + 20 = 120\n",
      "check : True\n",
      "end_game\n",
      "---------------4번째-----------\n",
      "start_game\n",
      "do_sum : 10 + -70 = -60\n",
      "temp_sum : 10 + -70 = -60\n",
      "check : True\n",
      "end_game\n"
     ]
    }
   ],
   "source": [
    "sum_list = [\n",
    "    [1, 2],\n",
    "    [3, -1],\n",
    "    [100, 20],\n",
    "    [10, -70] ]\n",
    "\n",
    "for x, y in enumerate(sum_list) :\n",
    "    print('---------------{}번째-----------'.format(x+1))\n",
    "    temp = my_class(y[0], y[1])\n",
    "    temp.check_sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 주소록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요 저는 서울시 서초구에 사는 20살 마리아입니다\n"
     ]
    }
   ],
   "source": [
    "from make_test import Person\n",
    "\n",
    "maria = Person('마리아', 20, '서울시 서초구')\n",
    "maria.greeting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>손흥민</td>\n",
       "      <td>28</td>\n",
       "      <td>영국 런던</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>송중기</td>\n",
       "      <td>36</td>\n",
       "      <td>서울 어딘가</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>꾸러기</td>\n",
       "      <td>10</td>\n",
       "      <td>양평</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1       2\n",
       "0  손흥민  28   영국 런던\n",
       "1  송중기  36  서울 어딘가\n",
       "2  꾸러기  10      양평"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "people_info = [\n",
    "    \n",
    "    ['손흥민', 28, '영국 런던'],\n",
    "    ['송중기', 36, '서울 어딘가'],\n",
    "    ['꾸러기', 10, '양평']\n",
    "]\n",
    "\n",
    "people_info = pd.DataFrame(people_info)\n",
    "people_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------1번째 사람---------\n",
      "\n",
      "안녕하세요 저는 영국 런던에 사는 28살 손흥민입니다\n",
      "\n",
      "----------2번째 사람---------\n",
      "\n",
      "안녕하세요 저는 서울 어딘가에 사는 36살 송중기입니다\n",
      "\n",
      "----------3번째 사람---------\n",
      "\n",
      "안녕하세요 저는 양평에 사는 10살 꾸러기입니다\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in range(len(people_info)) :\n",
    "    \n",
    "    print('----------{}번째 사람---------'.format(x+1))\n",
    "    print()\n",
    "    \n",
    "    person_info = list(people_info.iloc[x,:])\n",
    "    temp = Person(person_info[0], person_info[1], person_info[2])\n",
    "    temp.greeting()\n",
    "    \n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## matrix _ linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix1.shape : (2, 2), matrix2.shape : (2,), matrix3.shape : (2,)\n",
      "[5 5]\n",
      "[3 6]\n"
     ]
    }
   ],
   "source": [
    "from make_test import my_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "a = [[1, 2],\n",
    "     [1, 2]]\n",
    "\n",
    "# b = [[3],\n",
    "#     [1]]\n",
    "\n",
    "# c = [[-2],\n",
    "#     [1]]\n",
    "\n",
    "b = [3, 1]\n",
    "\n",
    "c = [-2, 1]\n",
    "\n",
    "a = np.array(a)\n",
    "b = np.array(b)\n",
    "c = np.array(c)\n",
    "\n",
    "mat = my_matrix(a, b, c)\n",
    "mat.shape()\n",
    "\n",
    "mat.Linear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 다중 상속"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아빠를 닮아 잘 생겼다.\n",
      "눈 부분을 닮았네\n",
      "엄마를 닮아 참 착하다.\n"
     ]
    }
   ],
   "source": [
    "from make_test import father, mother, sister\n",
    "\n",
    "girl = sister('아빠', '눈','엄마')\n",
    "girl.handsome()\n",
    "girl.kind()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 연습_GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ABCDEFG\n",
    "# 0123456"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 노드 연결 정보\n",
    "edges = np.array([[0 ,1],\n",
    "                 [2 ,3],\n",
    "                 [1 ,4],\n",
    "                 [3 ,4],\n",
    "                 [4 ,5],\n",
    "                 [4 ,6]])\n",
    "\n",
    "# 각 노드 특성 정보(H) = 7 X 4\n",
    "features = sp.csr_matrix([[1, 0, 0, 0],\n",
    "                          [0, 1, 0, 0],\n",
    "                          [1, 0, 0, 0],\n",
    "                          [0, 1, 0, 0],\n",
    "                          [0, 0, 1, 0],\n",
    "                          [0, 0, 0, 1],\n",
    "                          [0, 0, 0, 1]])\n",
    "\n",
    "# edge 특성 정보\n",
    "edge_features = [[3],\n",
    "                 [5],\n",
    "                 [1],\n",
    "                 [10],\n",
    "                 [6],\n",
    "                 [8]]\n",
    "\n",
    "# labels \n",
    "labels = np.array([1,\n",
    "                  4,\n",
    "                  5,\n",
    "                  2,\n",
    "                  6,\n",
    "                  8,\n",
    "                  7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===단위행렬 더하기 전===\n",
      "  (0, 1)\t1.0\n",
      "  (2, 3)\t1.0\n",
      "  (1, 4)\t1.0\n",
      "  (3, 4)\t1.0\n",
      "  (4, 5)\t1.0\n",
      "  (4, 6)\t1.0\n",
      "[[0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# direction matrix 생성\n",
    "adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:,0], edges[:,1])),\n",
    "             shape = (labels.shape[0], labels.shape[0]),\n",
    "             dtype = np.float32)\n",
    "\n",
    "\n",
    "## 확인\n",
    "print('===단위행렬 더하기 전===')\n",
    "print('{}'.format(adj))\n",
    "print(adj.toarray())\n",
    "print()\n",
    "\n",
    "## 고려할 것 : 단위행렬(자기자신의 정보) 전달\n",
    "#adj = adj + sp.eye(adj.shape[0])\n",
    "#print('===단위행렬 더한 후===')\n",
    "#print('{}'.format(adj))\n",
    "#print(adj.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def normalize(mx) :\n",
    "    rowsum = np.array(mx.sum(1)) # 각 노드 정보 개수\n",
    "    print('=====row별 feature 특성 합=====')\n",
    "    print(rowsum)\n",
    "\n",
    "    # r_inv\n",
    "    # 역행렬로 np.power 수행\n",
    "    r_inv = np.power(rowsum, 0).flatten() # 0, 1, # power : 0, 1, 8, 27, ,,, / 0, 1, 4, 9, ,,, / 0, 1, 0.5, 0.333, 0.25\n",
    "    print('===== 역행렬로 np.power 수행 =====')\n",
    "    r_inv[np.isinf(r_inv)] = 0 \n",
    "    print(r_inv)\n",
    "\n",
    "\n",
    "    # r_mat_inv\n",
    "    r_mat_inv = sp.diags(r_inv) # 행렬로 만들어줌\n",
    "    print(r_mat_inv.toarray())\n",
    "    \n",
    "    # 노드 adj 와 노드 feature 정보 행렬연산\n",
    "    print('=====adj, feature 행렬곱=====')\n",
    "    mx = r_mat_inv.dot(mx) \n",
    "\n",
    "    print(mx.toarray())\n",
    "    return mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====row별 feature 특성 합=====\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "===== 역행렬로 np.power 수행 =====\n",
      "[1 1 1 1 1 1 1]\n",
      "[[1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]]\n",
      "=====adj, feature 행렬곱=====\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# features : 현재 노드 + 연결된 노드 정보\n",
    "features = normalize(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====row별 feature 특성 합=====\n",
      "[[2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [1.]]\n",
      "===== 역행렬로 np.power 수행 =====\n",
      "[1. 1. 1. 1. 1. 1. 1.]\n",
      "[[1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]]\n",
      "=====adj, feature 행렬곱=====\n",
      "[[1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "adj = normalize(adj + sp.eye(adj.shape[0])) # 대각행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 4, 5, 2, 6, 8, 7])\n"
     ]
    }
   ],
   "source": [
    "idx_train = range(5)\n",
    "features = torch.FloatTensor(np.array(features.todense()))\n",
    "labels = torch.LongTensor(labels) # 원핫인코딩 된 label 중 해당하는 label이 몇 번 째인지\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "\n",
    "    # 노드\n",
    "    indices = torch.from_numpy(\n",
    "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64)) # vstack : 행 추가\n",
    "\n",
    "    # 노드 간 edge의 정보\n",
    "    values = torch.from_numpy(sparse_mx.data) # numpy.ndarray를 tensor로 올려줌\n",
    "\n",
    "    # 노드 개수, 특성 개수\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "\n",
    "    return torch.sparse.FloatTensor(indices, values, shape) # sparse : 크기에 맞게 값을 뿌려주는 것 같은데 규칙 잘 모르겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[0, 0, 1, 2, 2, 3, 1, 3, 4, 4, 5, 4, 6],\n",
       "                       [0, 1, 1, 2, 3, 3, 4, 4, 4, 5, 5, 6, 6]]),\n",
       "       values=tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       "       size=(7, 7), nnz=13, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj = sparse_mx_to_torch_sparse_tensor(adj)\n",
    "adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "A = adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def train(model, Loss, optimizer, num_epochs) :\n",
    "    \n",
    "    train_loss_arr = []\n",
    "    test_loss_arr = []\n",
    "\n",
    "    best_test_loss = 99999999\n",
    "    # early stopping 걸어줌\n",
    "    early_stop, early_stop_max = 0., 20.\n",
    "\n",
    "    best_ACC = 0\n",
    "    final_ACC = 0\n",
    "\n",
    "    for epoch in range(1, num_epochs+1) :\n",
    "\n",
    "        # forward pass\n",
    "        model.train()\n",
    "        output = model(features)\n",
    "        train_loss = criterion(output[idx_train], labels[idx_train])\n",
    "\n",
    "        # backward, optimize\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # loss 따로 저장해두고\n",
    "        train_loss_arr.append(train_loss.data)\n",
    "        if epoch % 100 == 1 :\n",
    "            print('epoch : ', epoch, 'train_loss : ', train_loss.item())\n",
    "            \n",
    "        \n",
    "\n",
    "        print('End training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class GCN_layer(nn.Module) :\n",
    "    def __init__(self, in_features, out_features, A) :\n",
    "        super(GCN_layer, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.A = A\n",
    "        self.fc = nn.Linear(in_features,\n",
    "                            out_features)\n",
    "\n",
    "    def forward(self, X) :\n",
    "        print('------------X------------')\n",
    "        print(X)\n",
    "\n",
    "        print('--------self.A-----------') # torch.spmm이 알아서 self.A를 numpy array로 바꾸고  X랑 행렬곱을 진행함\n",
    "        print(A)\n",
    "\n",
    "        print('--------이웃정보종합-------')\n",
    "        print(torch.spmm(self.A, X)) # A X X 행렬곱 한 값\n",
    "\n",
    "        print('--------END_GCN_layer--------')\n",
    "        \n",
    "        return self.fc(torch.spmm(self.A, X)) # 이웃 정보를 종합한다.\n",
    "    \n",
    "\n",
    "\n",
    "class GCN(nn.Module) :\n",
    "    def __init__(self, num_feature, num_class, A) : # feature개수, label개수\n",
    "        super(GCN, self).__init__()\n",
    "        self.feature_extractor = nn.Sequential( GCN_layer(num_feature, 16, A), # A : \n",
    "                                       nn.ReLU(),\n",
    "                                       GCN_layer(16, num_class, A))\n",
    "\n",
    "    def forward(self, X) :\n",
    "        return self.feature_extractor(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.unique().size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'A' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-8a6a744c3102>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# GCN 학습 후 epoch에 따른 loss 확인\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGCN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'A' is not defined"
     ]
    }
   ],
   "source": [
    "# GCN 학습 후 epoch에 따른 loss 확인\n",
    "model = GCN(features.size(1), labels.unique().size(0), A)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0001)\n",
    "train(model, criterion, optimizer, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------X------------\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1.]])\n",
      "--------self.A-----------\n",
      "tensor(indices=tensor([[0, 0, 1, 2, 2, 3, 1, 3, 4, 4, 5, 4, 6],\n",
      "                       [0, 1, 1, 2, 3, 3, 4, 4, 4, 5, 5, 6, 6]]),\n",
      "       values=tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
      "       size=(7, 7), nnz=13, layout=torch.sparse_coo)\n",
      "--------이웃정보종합-------\n",
      "tensor([[1., 1., 0., 0.],\n",
      "        [0., 1., 1., 0.],\n",
      "        [1., 1., 0., 0.],\n",
      "        [0., 1., 1., 0.],\n",
      "        [0., 0., 1., 2.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1.]])\n",
      "--------END_GCN_layer--------\n",
      "------------X------------\n",
      "tensor([[0.0000, 0.2218, 1.1766, 0.0000, 1.2408, 0.0000, 0.2497, 2.3071, 0.0000,\n",
      "         0.0680, 0.0400, 0.1231, 0.5789, 0.6298, 0.6331, 1.6679],\n",
      "        [0.0000, 0.6639, 0.6106, 0.0000, 0.5333, 0.2435, 0.0606, 1.6713, 0.0000,\n",
      "         1.0808, 0.5769, 1.1676, 1.7645, 0.0000, 1.5517, 1.3781],\n",
      "        [0.0000, 0.2218, 1.1766, 0.0000, 1.2408, 0.0000, 0.2497, 2.3071, 0.0000,\n",
      "         0.0680, 0.0400, 0.1231, 0.5789, 0.6298, 0.6331, 1.6679],\n",
      "        [0.0000, 0.6639, 0.6106, 0.0000, 0.5333, 0.2435, 0.0606, 1.6713, 0.0000,\n",
      "         1.0808, 0.5769, 1.1676, 1.7645, 0.0000, 1.5517, 1.3781],\n",
      "        [0.0000, 2.6168, 1.4902, 0.0000, 0.0000, 2.9360, 1.9609, 0.0000, 0.0000,\n",
      "         2.8784, 1.6903, 0.0000, 0.6417, 1.7886, 0.0000, 0.0000],\n",
      "        [0.0000, 1.2605, 1.3436, 0.0000, 0.0000, 1.6698, 1.6787, 0.0000, 0.0000,\n",
      "         1.2302, 0.5925, 0.0000, 0.0434, 1.3607, 0.0000, 0.0000],\n",
      "        [0.0000, 1.2605, 1.3436, 0.0000, 0.0000, 1.6698, 1.6787, 0.0000, 0.0000,\n",
      "         1.2302, 0.5925, 0.0000, 0.0434, 1.3607, 0.0000, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "--------self.A-----------\n",
      "tensor(indices=tensor([[0, 0, 1, 2, 2, 3, 1, 3, 4, 4, 5, 4, 6],\n",
      "                       [0, 1, 1, 2, 3, 3, 4, 4, 4, 5, 5, 6, 6]]),\n",
      "       values=tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
      "       size=(7, 7), nnz=13, layout=torch.sparse_coo)\n",
      "--------이웃정보종합-------\n",
      "tensor([[0.0000, 0.8857, 1.7872, 0.0000, 1.7741, 0.2435, 0.3103, 3.9784, 0.0000,\n",
      "         1.1487, 0.6169, 1.2906, 2.3433, 0.6298, 2.1848, 3.0460],\n",
      "        [0.0000, 3.2807, 2.1007, 0.0000, 0.5333, 3.1795, 2.0215, 1.6713, 0.0000,\n",
      "         3.9591, 2.2672, 1.1676, 2.4062, 1.7886, 1.5517, 1.3781],\n",
      "        [0.0000, 0.8857, 1.7872, 0.0000, 1.7741, 0.2435, 0.3103, 3.9784, 0.0000,\n",
      "         1.1487, 0.6169, 1.2906, 2.3433, 0.6298, 2.1848, 3.0460],\n",
      "        [0.0000, 3.2807, 2.1007, 0.0000, 0.5333, 3.1795, 2.0215, 1.6713, 0.0000,\n",
      "         3.9591, 2.2672, 1.1676, 2.4062, 1.7886, 1.5517, 1.3781],\n",
      "        [0.0000, 5.1379, 4.1774, 0.0000, 0.0000, 6.2756, 5.3184, 0.0000, 0.0000,\n",
      "         5.3387, 2.8752, 0.0000, 0.7284, 4.5100, 0.0000, 0.0000],\n",
      "        [0.0000, 1.2605, 1.3436, 0.0000, 0.0000, 1.6698, 1.6787, 0.0000, 0.0000,\n",
      "         1.2302, 0.5925, 0.0000, 0.0434, 1.3607, 0.0000, 0.0000],\n",
      "        [0.0000, 1.2605, 1.3436, 0.0000, 0.0000, 1.6698, 1.6787, 0.0000, 0.0000,\n",
      "         1.2302, 0.5925, 0.0000, 0.0434, 1.3607, 0.0000, 0.0000]],\n",
      "       grad_fn=<MmBackward>)\n",
      "--------END_GCN_layer--------\n",
      "예측값 : tensor([1, 2, 1, 2, 6, 6, 6])\n",
      "실제값 : tensor([1, 4, 5, 2, 6, 8, 7])\n",
      "tensor(42.8571, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "output = model(features)\n",
    "\n",
    "preds = output.max(1)[1].type_as(labels)\n",
    "print('예측값 : {}'.format(preds))\n",
    "print('실제값 : {}'.format(labels))\n",
    "\n",
    "correct = preds.eq(labels).double()\n",
    "correct = correct.sum()\n",
    "print(correct / len(labels) * 100) \n",
    "# 10 , 100: 42.8571\n",
    "# 1000 : 14.2857 ( 4로 수렴한다. )\n",
    "# 500 : 28. 57~\n",
    "# 10000 : 28.57"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# SAGEConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 노드 연결 정보\n",
    "edges = np.array([[0 ,1],\n",
    "                 [2 ,3],\n",
    "                 [1 ,4],\n",
    "                 [3 ,4],\n",
    "                 [4 ,5],\n",
    "                 [4 ,6]])\n",
    "\n",
    "# 각 노드 특성 정보(H) = 7 X 4\n",
    "features = sp.csr_matrix([[1, 0, 0, 0],\n",
    "                          [0, 1, 0, 0],\n",
    "                          [1, 0, 0, 0],\n",
    "                          [0, 1, 0, 0],\n",
    "                          [0, 0, 1, 0],\n",
    "                          [0, 0, 0, 1],\n",
    "                          [0, 0, 0, 1]])\n",
    "\n",
    "# edge 특성 정보\n",
    "edge_features = [[3],\n",
    "                 [5],\n",
    "                 [1],\n",
    "                 [10],\n",
    "                 [6],\n",
    "                 [8]]\n",
    "\n",
    "# labels \n",
    "labels = np.array([1,\n",
    "                  4,\n",
    "                  5,\n",
    "                  2,\n",
    "                  6,\n",
    "                  8,\n",
    "                  7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===단위행렬 더하기 전===\n",
      "  (0, 1)\t1.0\n",
      "  (2, 3)\t1.0\n",
      "  (1, 4)\t1.0\n",
      "  (3, 4)\t1.0\n",
      "  (4, 5)\t1.0\n",
      "  (4, 6)\t1.0\n",
      "[[0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# direction matrix 생성\n",
    "adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:,0], edges[:,1])),\n",
    "             shape = (labels.shape[0], labels.shape[0]),\n",
    "             dtype = np.float32)\n",
    "\n",
    "\n",
    "## 확인\n",
    "print('===단위행렬 더하기 전===')\n",
    "print('{}'.format(adj))\n",
    "print(adj.toarray())\n",
    "print()\n",
    "\n",
    "## 고려할 것 : 단위행렬(자기자신의 정보) 전달\n",
    "#adj = adj + sp.eye(adj.shape[0])\n",
    "#print('===단위행렬 더한 후===')\n",
    "#print('{}'.format(adj))\n",
    "#print(adj.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def normalize(mx) :\n",
    "    rowsum = np.array(mx.sum(1)) # 각 노드 정보 개수\n",
    "    print('=====row별 feature 특성 합=====')\n",
    "    print(rowsum)\n",
    "\n",
    "    # r_inv\n",
    "    # 역행렬로 np.power 수행\n",
    "    r_inv = np.power(rowsum, 0).flatten() # 0, 1, # power : 0, 1, 8, 27, ,,, / 0, 1, 4, 9, ,,, / 0, 1, 0.5, 0.333, 0.25\n",
    "    print('===== 역행렬로 np.power 수행 =====')\n",
    "    r_inv[np.isinf(r_inv)] = 0 \n",
    "    print(r_inv)\n",
    "\n",
    "\n",
    "    # r_mat_inv\n",
    "    r_mat_inv = sp.diags(r_inv) # 행렬로 만들어줌\n",
    "    print(r_mat_inv.toarray())\n",
    "    \n",
    "    # 노드 adj 와 노드 feature 정보 행렬연산\n",
    "    print('=====adj, feature 행렬곱=====')\n",
    "    mx = r_mat_inv.dot(mx) \n",
    "\n",
    "    print(mx.toarray())\n",
    "    return mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====row별 feature 특성 합=====\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "===== 역행렬로 np.power 수행 =====\n",
      "[1 1 1 1 1 1 1]\n",
      "[[1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]]\n",
      "=====adj, feature 행렬곱=====\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# features : 현재 노드 + 연결된 노드 정보\n",
    "features = normalize(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====row별 feature 특성 합=====\n",
      "[[2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [1.]]\n",
      "===== 역행렬로 np.power 수행 =====\n",
      "[1. 1. 1. 1. 1. 1. 1.]\n",
      "[[1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]]\n",
      "=====adj, feature 행렬곱=====\n",
      "[[1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "adj = normalize(adj + sp.eye(adj.shape[0])) # 대각행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 4, 5, 2, 6, 8, 7])\n"
     ]
    }
   ],
   "source": [
    "idx_train = range(5)\n",
    "features = torch.FloatTensor(np.array(features.todense()))\n",
    "labels = torch.LongTensor(labels) # 원핫인코딩 된 label 중 해당하는 label이 몇 번 째인지\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "\n",
    "    # 노드\n",
    "    indices = torch.from_numpy(\n",
    "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64)) # vstack : 행 추가\n",
    "\n",
    "    # 노드 간 edge의 정보\n",
    "    values = torch.from_numpy(sparse_mx.data) # numpy.ndarray를 tensor로 올려줌\n",
    "\n",
    "    # 노드 개수, 특성 개수\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "\n",
    "    return torch.sparse.LongTensor(indices, values, shape) # sparse : 크기에 맞게 값을 뿌려주는 것 같은데 규칙 잘 모르겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[0, 0, 1, 2, 2, 3, 1, 3, 4, 4, 5, 4, 6],\n",
       "                       [0, 1, 1, 2, 3, 3, 4, 4, 4, 5, 5, 6, 6]]),\n",
       "       values=tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       "       size=(7, 7), nnz=13, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj = sparse_mx_to_torch_sparse_tensor(adj)\n",
    "adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "A = adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_channels : (4, 4)\n",
      "lin_l : Linear(in_features=4, out_features=7, bias=True)\n",
      "lin_r : Linear(in_features=4, out_features=7, bias=False)\n",
      "tensor(indices=tensor([[0, 0, 1, 2, 2, 3, 1, 3, 4, 4, 5, 4, 6],\n",
      "                       [0, 1, 1, 2, 3, 3, 4, 4, 4, 5, 5, 6, 6]]),\n",
      "       values=tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
      "       size=(7, 7), nnz=13, layout=torch.sparse_coo)\n",
      "(tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1.]]), tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1.]]))\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-a8d23f261e40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSAGEConv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\연구\\module_mine\\new2\\raw_graphsage.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, edge_index, size)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# edge_index는 propagate 오류남\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlin_l\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# lin_l에 변수 두개 들어가야하는데 하나만 들어감 어떻게 계산?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py\u001b[0m in \u001b[0;36mpropagate\u001b[1;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[0;32m    213\u001b[0m                 \u001b[0maggregate\u001b[0m \u001b[0mmessages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mto\u001b[0m \u001b[0mupdate\u001b[0m \u001b[0mnode\u001b[0m \u001b[0membeddings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m         \"\"\"\n\u001b[1;32m--> 215\u001b[1;33m         \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__check_input__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[1;31m# Run \"fused\" message and aggregation (if applicable).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py\u001b[0m in \u001b[0;36m__check_input__\u001b[1;34m(self, edge_index, size)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m             \u001b[1;32massert\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from raw_graphsage import SAGEConv\n",
    "\n",
    "model = SAGEConv(4, 7)\n",
    "model(features, edge_index = A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-253064b5f801>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSAGEConv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\torch_geometric\\nn\\conv\\sage_conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, edge_index, size)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;31m# propagate_type: (x: OptPairTensor)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlin_l\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py\u001b[0m in \u001b[0;36mpropagate\u001b[1;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[0;32m    213\u001b[0m                 \u001b[0maggregate\u001b[0m \u001b[0mmessages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mto\u001b[0m \u001b[0mupdate\u001b[0m \u001b[0mnode\u001b[0m \u001b[0membeddings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m         \"\"\"\n\u001b[1;32m--> 215\u001b[1;33m         \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__check_input__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[1;31m# Run \"fused\" message and aggregation (if applicable).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py\u001b[0m in \u001b[0;36m__check_input__\u001b[1;34m(self, edge_index, size)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m             \u001b[1;32massert\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "model = SAGEConv(4, 7)\n",
    "model(features, edge_index = A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch_geometric.nn.conv.sage_conv.SAGEConv.forward(self, x: Union[torch.Tensor, Tuple[torch.Tensor, Union[torch.Tensor, NoneType]]], edge_index: Union[torch.Tensor, torch_sparse.tensor.SparseTensor], size: Union[Tuple[int, int], NoneType] = None) -> torch.Tensor>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "\n",
    "SAGEConv(4, 7)\n",
    "SAGEConv.forward\n",
    "#SAGEConv.message \n",
    "#SAGEConv.message_and_aggregate # self, adj_t, x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def train(model, Loss, optimizer, num_epochs) :\n",
    "    \n",
    "    train_loss_arr = []\n",
    "    test_loss_arr = []\n",
    "\n",
    "    best_test_loss = 99999999\n",
    "    # early stopping 걸어줌\n",
    "    early_stop, early_stop_max = 0., 20.\n",
    "\n",
    "    best_ACC = 0\n",
    "    final_ACC = 0\n",
    "\n",
    "    for epoch in range(1, num_epochs+1) :\n",
    "\n",
    "        # forward pass\n",
    "        model.train()\n",
    "        output = model(features) #input\n",
    "        train_loss = criterion(output[idx_train], labels[idx_train])\n",
    "\n",
    "        # backward, optimize\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # loss 따로 저장해두고\n",
    "        train_loss_arr.append(train_loss.data)\n",
    "        \n",
    "        if epoch % 100 == 1 :\n",
    "            print('epoch : ', epoch, 'train_loss : ', train_loss.item())\n",
    "\n",
    "        print('End training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 쌓을 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAGENet(\n",
      "  (feature_extractor): Sequential(\n",
      "    (0): SAGEConv(4, 16)\n",
      "    (1): ReLU()\n",
      "    (2): SAGEConv(16, 7)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import SAGEConv\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "class SAGENet(torch.nn.Module) :\n",
    "    def __init__(self, num_feature, num_class, A) :\n",
    "        super(SAGENet, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        \n",
    "        self.feature_extractor = nn.Sequential(SAGEConv(num_feature, 16, A),\n",
    "                                              nn.ReLU(),\n",
    "                                              SAGEConv(16, num_class, A))\n",
    "        \n",
    "#        mlp1 = ###\n",
    "#        self.conv1 = SAGEConv(###)\n",
    "#        mlp2 = ###\n",
    "#        self.conv2 = SAGEConv(###)\n",
    "#        self.classifier = Linear(32, )###)\n",
    "                                 \n",
    "    def forward(self, X) :\n",
    "        \n",
    "        return self.feature_extractor(X)\n",
    "    \n",
    "#        edge_index = knn_graph(pos, k=16, batch = batch, loop = False)\n",
    "                                 \n",
    "#        x = self.conv1(x = None, edge_index = edge_index)\n",
    "#        x = x.relu()\n",
    "#        x = self.conv2(x = x, edge_index = edge_index)\n",
    "#        x = x.relu()\n",
    "            \n",
    "#        x = global_max_pool(x, batch)\n",
    "        \n",
    "            \n",
    "        # return self.classifier(x)\n",
    "            \n",
    "model = SAGENet(4, 7, adj)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[0, 0, 1, 2, 2, 3, 1, 3, 4, 4, 5, 4, 6],\n",
       "                       [0, 1, 1, 2, 3, 3, 4, 4, 4, 5, 5, 6, 6]]),\n",
       "       values=tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       "       size=(7, 7), nnz=13, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'edge_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-e2400572a824>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-35-32f84cb0bd0e>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, Loss, optimizer, num_epochs)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m# forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'edge_index'"
     ]
    }
   ],
   "source": [
    "model = SAGEConv(features.size(1), labels.unique().size(0))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0001)\n",
    "train(model, criterion, optimizer, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 대기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------reset_parameters----------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SAGE(10, 4)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from new_graphsage import SAGE\n",
    "\n",
    "SAGE(10, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "#노드 연결 정보\n",
    "edges = np.array([[0 ,1],\n",
    "                 [2 ,3],\n",
    "                 [1 ,4],\n",
    "                 [3 ,4],\n",
    "                 [4 ,5],\n",
    "                 [4 ,6]])\n",
    "\n",
    "# 각 노드 특성 정보(H) = 7 X 4\n",
    "features = sp.csr_matrix([[1, 0, 0, 0],\n",
    "                          [0, 1, 0, 0],\n",
    "                          [1, 0, 0, 0],\n",
    "                          [0, 1, 0, 0],\n",
    "                          [0, 0, 1, 0],\n",
    "                          [0, 0, 0, 1],\n",
    "                          [0, 0, 0, 1]])\n",
    "\n",
    "# edge 특성 정보\n",
    "edge_features = [[3],\n",
    "                 [5],\n",
    "                 [1],\n",
    "                 [10],\n",
    "                 [6],\n",
    "                 [8]]\n",
    "\n",
    "# labels \n",
    "labels = np.array([1,\n",
    "                  4,\n",
    "                  5,\n",
    "                  2,\n",
    "                  6,\n",
    "                  3,\n",
    "                  0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[6, 2], x=[7, 1])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "edge_index = torch.tensor([[0 ,1],\n",
    "                             [2 ,3],\n",
    "                             [1 ,4],\n",
    "                             [3 ,4],\n",
    "                             [4 ,5],\n",
    "                             [4 ,6]], dtype=torch.long)\n",
    "x = torch.tensor([[0], [1], [2], [3], [4], [5], [6]], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "data\n",
    "\n",
    "# edge 개수 : 6\n",
    "# node 개수 : 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===단위행렬 더하기 전===\n",
      "  (0, 1)\t1.0\n",
      "  (2, 3)\t1.0\n",
      "  (1, 4)\t1.0\n",
      "  (3, 4)\t1.0\n",
      "  (4, 5)\t1.0\n",
      "  (4, 6)\t1.0\n",
      "[[0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 단위 행렬 더해주기\n",
    "# direction matrix 생성\n",
    "adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:,0], edges[:,1])),\n",
    "             shape = (labels.shape[0], labels.shape[0]),\n",
    "             dtype = np.float32)\n",
    "\n",
    "\n",
    "## 확인\n",
    "print('===단위행렬 더하기 전===')\n",
    "print('{}'.format(adj))\n",
    "print(adj.toarray())\n",
    "print()\n",
    "\n",
    "## 고려할 것 : 단위행렬(자기자신의 정보) 전달\n",
    "#adj = adj + sp.eye(adj.shape[0])\n",
    "#print('===단위행렬 더한 후===')\n",
    "#print('{}'.format(adj))\n",
    "#print(adj.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(mx) :\n",
    "    rowsum = np.array(mx.sum(1)) # 각 노드 정보 개수\n",
    "    print('=====row별 feature 특성 합=====')\n",
    "    print(rowsum)\n",
    "\n",
    "    # r_inv\n",
    "    # 역행렬로 np.power 수행\n",
    "    r_inv = np.power(rowsum, 0).flatten() # 0, 1, # power : 0, 1, 8, 27, ,,, / 0, 1, 4, 9, ,,, / 0, 1, 0.5, 0.333, 0.25\n",
    "    print('===== 역행렬로 np.power 수행 =====')\n",
    "    r_inv[np.isinf(r_inv)] = 0 \n",
    "    print(r_inv)\n",
    "\n",
    "\n",
    "    # r_mat_inv\n",
    "    r_mat_inv = sp.diags(r_inv) # 행렬로 만들어줌\n",
    "    print(r_mat_inv.toarray())\n",
    "    \n",
    "    # 노드 adj 와 노드 feature 정보 행렬연산\n",
    "    print('=====adj, feature 행렬곱=====')\n",
    "    mx = r_mat_inv.dot(mx) \n",
    "\n",
    "    print(mx.toarray())\n",
    "    return mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===단위행렬 더한 후===\n",
      "[[1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]]\n",
      "======1번째======\n",
      "[[1. 1. 0. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [1. 1. 0. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 2.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]]\n",
      "======2번째======\n",
      "[[1. 2. 1. 0.]\n",
      " [0. 1. 2. 2.]\n",
      " [1. 2. 1. 0.]\n",
      " [0. 1. 2. 2.]\n",
      " [0. 0. 1. 4.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# num_nodes = max + 1 = 7\n",
    "# num_edges = len(edges) = 6\n",
    "\n",
    "num_nodes = 7\n",
    "num_edges = len(edges)\n",
    "\n",
    "# direction matrix 생성\n",
    "adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\n",
    "                    shape=(labels.shape[0], labels.shape[0]),\n",
    "                    dtype=np.float32)\n",
    "\n",
    "## 고려할 것 : 단위행렬(자기자신의 정보) 전달\n",
    "adj = adj + sp.eye(adj.shape[0])\n",
    "print('===단위행렬 더한 후===')\n",
    "print(adj.toarray())\n",
    "\n",
    "# edge정보를 어떻게 맞춰줄것인가_dimension\n",
    "\n",
    "# 행렬곱을 위한 array \n",
    "adj_arr = adj.toarray()\n",
    "features_arr = features.toarray()\n",
    "\n",
    "# hop 에 따라 정보 전달\n",
    "hop = 2\n",
    "for idx in range(hop) :\n",
    "    features_arr = np.matmul(adj_arr, features_arr) # 여기에 weight 곱하기, bias 더하기\n",
    "    print('======{0}번째======'.format(idx+1))\n",
    "    print('{}'.format(features_arr))\n",
    "    \n",
    "    \n",
    "# feature 정보 학습, label regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====row별 feature 특성 합=====\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "===== 역행렬로 np.power 수행 =====\n",
      "[1 1 1 1 1 1 1]\n",
      "[[1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]]\n",
      "=====adj, feature 행렬곱=====\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]]\n",
      "=====row별 feature 특성 합=====\n",
      "[[3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]]\n",
      "===== 역행렬로 np.power 수행 =====\n",
      "[1. 1. 1. 1. 1. 1. 1.]\n",
      "[[1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]]\n",
      "=====adj, feature 행렬곱=====\n",
      "[[2. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 2. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 2. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 2. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 2. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 2. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 2.]]\n",
      "tensor([1, 4, 5, 2, 6, 3, 0])\n"
     ]
    }
   ],
   "source": [
    "# features : 현재 노드 + 연결된 노드 정보\n",
    "features = normalize(features)\n",
    "\n",
    "adj = normalize(adj + sp.eye(adj.shape[0])) # 대각행렬\n",
    "\n",
    "idx_train = range(5)\n",
    "features = torch.FloatTensor(np.array(features.todense()))\n",
    "labels = torch.LongTensor(labels) # 원핫인코딩 된 label 중 해당하는 label이 몇 번 째인지\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "\n",
    "    # 노드\n",
    "    indices = torch.from_numpy(\n",
    "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64)) # vstack : 행 추가\n",
    "\n",
    "    # 노드 간 edge의 정보\n",
    "    values = torch.from_numpy(sparse_mx.data) # numpy.ndarray를 tensor로 올려줌\n",
    "\n",
    "    # 노드 개수, 특성 개수\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "\n",
    "    return torch.sparse.FloatTensor(indices, values, shape) # sparse : 크기에 맞게 값을 뿌려주는 것 같은데 규칙 잘 모르겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[0, 0, 1, 2, 2, 3, 1, 3, 4, 4, 5, 4, 6],\n",
       "                       [0, 1, 1, 2, 3, 3, 4, 4, 4, 5, 5, 6, 6]]),\n",
       "       values=tensor([2., 1., 2., 2., 1., 2., 1., 1., 2., 1., 2., 1., 2.]),\n",
       "       size=(7, 7), nnz=13, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj = sparse_mx_to_torch_sparse_tensor(adj)\n",
    "adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu 연결\n",
    "import torch\n",
    "torch.manual_seed(777)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Target 1 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-e6c1c3ad7195>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# cost/loss function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhypothesis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m#    print('epoch = {}, {}, cost : {}'.format(step, hypothesis, cost.item()))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[0;32m    962\u001b[0m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2466\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2467\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2468\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2470\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2262\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[0;32m   2263\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2264\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2265\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2266\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: Target 1 is out of bounds."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "\n",
    "linear1 = torch.nn.Linear(7, 7, bias=True)\n",
    "activate = torch.nn.ReLU()\n",
    "\n",
    "model = torch.nn.Sequential(linear1, activate)\n",
    "\n",
    "# define cost / loss & optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1)\n",
    "\n",
    "for step in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(adj)\n",
    "\n",
    "    # cost/loss function\n",
    "    cost = criterion(hypothesis, labels)\n",
    "    \n",
    "#    print('epoch = {}, {}, cost : {}'.format(step, hypothesis, cost.item()))\n",
    "    \n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 1000 == 0:\n",
    "        print(step, cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.]])\n",
      "\n",
      "Hypothesis:  [[ 0.         0.         0.         0.         0.         0.\n",
      "   0.       ]\n",
      " [ 0.         0.         0.         0.        10.426947   0.\n",
      "   0.       ]\n",
      " [ 0.         0.         0.         0.         0.        23.866125\n",
      "   0.       ]\n",
      " [ 0.         0.        17.498901   0.         0.         6.5127773\n",
      "   0.       ]\n",
      " [ 0.         0.         0.         0.         0.         0.\n",
      "   0.       ]\n",
      " [ 0.         0.         0.        20.451033   0.         0.\n",
      "   0.       ]\n",
      " [21.309532   0.         0.         0.         0.         0.\n",
      "   0.       ]] \n",
      "Correct:  [[0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]] \n",
      "Accuracy:  16.326530277729034 %\n"
     ]
    }
   ],
   "source": [
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "with torch.no_grad():\n",
    "    hypothesis = model(adj)\n",
    "    predicted = (hypothesis > 0.5).float()\n",
    "    print(predicted)\n",
    "    accuracy = (predicted == labels).float().mean()\n",
    "    print('\\nHypothesis: ', hypothesis.detach().cpu().numpy(), \n",
    "          '\\nCorrect: ', predicted.detach().cpu().numpy(), \n",
    "          '\\nAccuracy: ', accuracy.item() * 100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### gcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "\n",
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNConv, self).__init__(aggr='add')  # \"Add\" aggregation (Step 5).\n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "\n",
    "        # Step 1: Add self-loops to the adjacency matrix.\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        # Step 2: Linearly transform node feature matrix.\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # Step 3: Compute normalization.\n",
    "        row, col = edge_index\n",
    "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        # Step 4-5: Start propagating messages.\n",
    "        return self.propagate(edge_index, x=x, norm=norm)\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        # x_j has shape [E, out_channels]\n",
    "\n",
    "        # Step 4: Normalize node features.\n",
    "        return norm.view(-1, 1) * x_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Got 6 and 2 in dimension 0 (The offending index is 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-c1bed2b4781f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mconv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGCNConv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-3b7cc638af9b>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, edge_index)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m# Step 1: Add self-loops to the adjacency matrix.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madd_self_loops\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_nodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# Step 2: Linearly transform node feature matrix.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\torch_geometric\\utils\\loop.py\u001b[0m in \u001b[0;36madd_self_loops\u001b[1;34m(edge_index, edge_weight, fill_value, num_nodes)\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0medge_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0medge_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloop_weight\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m     \u001b[0medge_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloop_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Got 6 and 2 in dimension 0 (The offending index is 1)"
     ]
    }
   ],
   "source": [
    "conv = GCNConv(16, 32)\n",
    "x = conv(x, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "242px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
