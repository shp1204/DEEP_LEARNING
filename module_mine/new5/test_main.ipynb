{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============epoch : 0 cost : 18.006546020507812==========\n",
      "============epoch : 100 cost : 8.077032089233398==========\n",
      "============epoch : 200 cost : 4.821557998657227==========\n",
      "============epoch : 300 cost : 2.9079031944274902==========\n",
      "============epoch : 400 cost : 1.706923007965088==========\n",
      "============epoch : 500 cost : 0.9723665714263916==========\n",
      "============epoch : 600 cost : 0.5366989374160767==========\n",
      "============epoch : 700 cost : 0.28656110167503357==========\n",
      "============epoch : 800 cost : 0.14770159125328064==========\n",
      "============epoch : 900 cost : 0.07327389717102051==========\n",
      "============epoch : 1000 cost : 0.0348505824804306==========\n",
      "==================================================\n",
      "예측값 : tensor([ 2.2038e+00,  3.2295e+00,  5.0636e+00, -2.0289e-03,  6.8808e+00,\n",
      "         3.9942e+00,  2.0954e+00,  9.6035e+00], grad_fn=<ViewBackward>)\n",
      "실제값 : [ 2  3  5  0  7  4  2 10]\n",
      "최종 cost값 : 0.0348505824804306\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as Func\n",
    "import torch.optim as optimizer\n",
    "from torch.nn import Linear\n",
    "from preprocessing import *\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "# data\n",
    "# 노드 연결 정보 # 변하지 않음.\n",
    "#edges = np.array([[0, 1], [2, 3], [1, 4], [3, 4], [4, 5], [4, 6]])\n",
    "# # # 각 노드 특성 정보(H) = 7 X 4 # 시간 지나면서 계속 변함\n",
    "#features = sp.csr_matrix([[1, 0, 0, 0], [0, 1, 0, 0], [1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1], [0, 0, 0, 1]])\n",
    "# # # edge 특성 정보 # 시간 지나면서 계속 변함\n",
    "#edge_features = [[3], [5], [1], [10], [6], [8]]\n",
    "# # # labels # train용은 안 변함.\n",
    "#labels = np.array([1, 4, 5, 2, 6, 3, 0])\n",
    "\n",
    "edges = np.array([[0,1], [1,2], [2,4], [3,4], [4,5], [5,6], [5,7]])\n",
    "features = sp.csr_matrix([[1,2,3],[2,3,5],[1,3,7],[4,5,7],[0,2,3],[5,6,7],[8,3,1],[9,5,7]])\n",
    "edge_features = [[0],[0],[1],[2],[6],[4],[10]]\n",
    "labels = np.array([2, 3, 5, 0, 7, 4, 2, 10])\n",
    "\n",
    "# edges = np.array([[0,1],[1,2],[2,3],[3,4],[3,5],[3,6],[4,7],[5,8],[6,9],[9,10]])\n",
    "# features = sp.csr_matrix([[5,3,2],[1,5,7],[6,5,8],[9,8,2],[5,6,2],[8,6,5],[3,4,7],[9,1,4],[7,7,3],[1,6,5],[9,10,1]])\n",
    "# edge_features = [[2],[1],[3],[15],[7],[9],[5],[8],[3],[6]]\n",
    "# labels = np.array([1, 1, 3, 1, 4, 2, 9, 12, 5, 6, 13])\n",
    "\n",
    "def normalize(X):\n",
    "    nom = X - X.min(axis=0)\n",
    "    denom = X.max(axis=0) - X.min(axis=0)\n",
    "    denom[denom == 0] = 1\n",
    "    return nom / denom\n",
    "\n",
    "# 전처리\n",
    "method = 'mean'\n",
    "\n",
    "\n",
    "features = normalize(features.toarray())\n",
    "pp = preprocessing(edges, features, edge_features, method) # method ? sum, mean, min, max, linear\n",
    "\n",
    "\n",
    "\n",
    "# 단위행렬 더하기\n",
    "A = pp.coo().toarray()\n",
    "# edge_feature의 크기를 feature와 맞춰주기\n",
    "\n",
    "if method == 'linear':\n",
    "    edge_encoder = Linear(len(edge_features), features.shape[0])\n",
    "    edge_encoder.reset_parameters()\n",
    "    edge_features = torch.Tensor(np.array(edge_features))\n",
    "    edge_features = Func.relu(edge_encoder(edge_features.T).T).detach().numpy()\n",
    "\n",
    "else:\n",
    "    edge_features = pp.convert()\n",
    "\n",
    "# 행\n",
    "row = len(labels)\n",
    "# 열\n",
    "col = features.shape[1] + 1\n",
    "\n",
    "\n",
    "# train\n",
    "# 학습 parameter 설정\n",
    "# weight 5개로 설정 -> 추후에 hop개수에 따라 설정 가능하도록 변경\n",
    "\n",
    "# hop1\n",
    "AFW = torch.FloatTensor(np.array(np.matmul(A, features)))\n",
    "weight1 = Parameter(torch.Tensor(np.random.rand(AFW.size()[1],\n",
    "                                                AFW.size()[1])))  # weight for hop1 _ F\n",
    "weight2 = Parameter(torch.Tensor(np.random.rand(AFW.size()[1],\n",
    "                                                AFW.size()[1])))  # weight for hop2 _ F\n",
    "\n",
    "# hop2\n",
    "AeFW = torch.FloatTensor(np.array(np.matmul(A, edge_features)))\n",
    "weight3 = Parameter(torch.Tensor(np.random.rand(AeFW.size()[1],\n",
    "                                                AeFW.size()[1])))  # weight for hop2 _ edge_F\n",
    "weight4 = Parameter(torch.Tensor(np.random.rand(AeFW.size()[1],\n",
    "                                                AeFW.size()[1])))  # weight for hop2 _ edge_F\n",
    "\n",
    "# regression\n",
    "weight5 = Parameter(torch.Tensor(np.random.rand(col, 1)))  # weight for regression\n",
    "bias = Parameter(torch.Tensor(np.random.rand(row, 1)))\n",
    "\n",
    "optims = optimizer.Adam([weight1, weight2, weight3, weight4, weight5, bias], lr=0.01)\n",
    "\n",
    "torch.nn.init.xavier_uniform_(weight1)\n",
    "torch.nn.init.xavier_uniform_(weight2)\n",
    "torch.nn.init.xavier_uniform_(weight3)\n",
    "torch.nn.init.xavier_uniform_(weight4)\n",
    "torch.nn.init.xavier_uniform_(weight5)\n",
    "\n",
    "## train\n",
    "for i in range(1000 + 1):\n",
    "\n",
    "    #print(AFW)\n",
    "    AFW = Func.relu(torch.Tensor(normalize(torch.matmul(AFW, weight1).detach().numpy())))\n",
    "    #print(AFW)\n",
    "    AFW = Func.relu(torch.Tensor(normalize(torch.matmul(AFW, weight2).detach().numpy())))\n",
    "    #print(AFW)\n",
    "\n",
    "    #print(AeFW)\n",
    "    AeFW = Func.relu(torch.Tensor(normalize(torch.matmul(AeFW, weight3).detach().numpy())))\n",
    "    #print(AeFW)\n",
    "    AeFW = Func.relu(torch.Tensor(normalize(torch.matmul(AeFW, weight4).detach().numpy())))\n",
    "    #print(AeFW)\n",
    "\n",
    "    # 최종 F, eF를 concat\n",
    "    newF = torch.cat([torch.Tensor(AFW),\n",
    "                    torch.Tensor(AeFW)], dim=-1)\n",
    "\n",
    "    # print(weight5)\n",
    "\n",
    "    # regression\n",
    "    # backward로 갈 때 결국 hypothesis에 대한 weight, bias만 수정된다.\n",
    "    # weight 1, 2, 3, 4 는 어떻게 정보 전달할지 ?///////// ....\n",
    "\n",
    "    hypothesis = torch.matmul(newF, weight5) + bias\n",
    "    cost = Func.mse_loss(hypothesis.reshape(len(labels), ),\n",
    "                      torch.FloatTensor(labels))\n",
    "    # print(hypothesis)\n",
    "    # print(hypothesis.reshape(len(labels),))\n",
    "    # print(cost)\n",
    "\n",
    "    optims.zero_grad()\n",
    "    cost.backward()\n",
    "    optims.step()\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print('============epoch : {} cost : {}=========='.format(i, cost))\n",
    "\n",
    "print('=' * 50)\n",
    "print('예측값 : {}'.format(hypothesis.flatten()))\n",
    "print('실제값 : {}'.format(labels))\n",
    "print('최종 cost값 : {}'.format(cost))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
