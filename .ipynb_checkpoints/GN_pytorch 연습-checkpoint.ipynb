{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# GPU 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct 29 09:54:59 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 456.71       Driver Version: 456.71       CUDA Version: 11.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 105... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| 45%   24C    P8    N/A /  75W |    390MiB /  4096MiB |      3%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1416    C+G   ...kyb3d8bbwe\\Calculator.exe    N/A      |\n",
      "|    0   N/A  N/A      2832    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A      6492    C+G   ...nputApp\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A      7972    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      8128    C+G   ...ekyb3d8bbwe\\commsapps.exe    N/A      |\n",
      "|    0   N/A  N/A     10684    C+G   ...oot\\Office16\\POWERPNT.EXE    N/A      |\n",
      "|    0   N/A  N/A     11140    C+G   ...3d8bbwe\\MicrosoftEdge.exe    N/A      |\n",
      "|    0   N/A  N/A     11328    C+G   ...8wekyb3d8bbwe\\Cortana.exe    N/A      |\n",
      "|    0   N/A  N/A     11408    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     11880    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n",
      "|    0   N/A  N/A     14292    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     14892    C+G   ...8wekyb3d8bbwe\\XboxApp.exe    N/A      |\n",
      "|    0   N/A  N/A     15932    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A     16536    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     17780    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
      "|    0   N/A  N/A     18628    C+G   ...b3d8bbwe\\WinStore.App.exe    N/A      |\n",
      "|    0   N/A  N/A     19568    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices  1\n",
      "Current cuda device  0\n",
      "GeForce GTX 1050 Ti\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print ('Available devices ', torch.cuda.device_count())\n",
    "print ('Current cuda device ', torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.2\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.6.0.html\n",
      "Collecting torch-scatter==latest+cu102\n",
      "  Using cached https://pytorch-geometric.com/whl/torch-1.6.0/torch_scatter-latest%2Bcu102-cp38-cp38-win_amd64.whl (2.4 MB)\n",
      "Installing collected packages: torch-scatter\n",
      "  Attempting uninstall: torch-scatter\n",
      "    Found existing installation: torch-scatter 2.0.5\n",
      "    Uninstalling torch-scatter-2.0.5:\n",
      "      Successfully uninstalled torch-scatter-2.0.5\n",
      "Successfully installed torch-scatter-2.0.5\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.6.0.html\n",
      "Collecting torch-sparse==latest+cu102\n",
      "  Using cached https://pytorch-geometric.com/whl/torch-1.6.0/torch_sparse-latest%2Bcu102-cp38-cp38-win_amd64.whl (950 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\won\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from torch-sparse==latest+cu102) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\won\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from scipy->torch-sparse==latest+cu102) (1.18.5)\n",
      "Installing collected packages: torch-sparse\n",
      "  Attempting uninstall: torch-sparse\n",
      "    Found existing installation: torch-sparse 0.6.7\n",
      "    Uninstalling torch-sparse-0.6.7:\n",
      "      Successfully uninstalled torch-sparse-0.6.7\n",
      "Successfully installed torch-sparse-0.6.7\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.6.0.html\n",
      "Collecting torch-cluster==latest+cu102\n",
      "  Using cached https://pytorch-geometric.com/whl/torch-1.6.0/torch_cluster-latest%2Bcu102-cp38-cp38-win_amd64.whl (584 kB)\n",
      "Installing collected packages: torch-cluster\n",
      "  Attempting uninstall: torch-cluster\n",
      "    Found existing installation: torch-cluster 1.5.7\n",
      "    Uninstalling torch-cluster-1.5.7:\n",
      "      Successfully uninstalled torch-cluster-1.5.7\n",
      "Successfully installed torch-cluster-1.5.7\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.6.0.html\n",
      "Collecting torch-spline-conv==latest+cu102\n",
      "  Using cached https://pytorch-geometric.com/whl/torch-1.6.0/torch_spline_conv-latest%2Bcu102-cp38-cp38-win_amd64.whl (261 kB)\n",
      "Installing collected packages: torch-spline-conv\n",
      "  Attempting uninstall: torch-spline-conv\n",
      "    Found existing installation: torch-spline-conv 1.2.0\n",
      "    Uninstalling torch-spline-conv-1.2.0:\n",
      "      Successfully uninstalled torch-spline-conv-1.2.0\n",
      "Successfully installed torch-spline-conv-1.2.0\n",
      "Requirement already satisfied: torch-geometric in c:\\users\\won\\anaconda3\\envs\\cpu_env\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numba in c:\\users\\won\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from torch-geometric) (0.51.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\won\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from torch-geometric) (1.1.3)\n",
      "Requirement already satisfied: torch in c:\\users\\won\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from torch-geometric) (1.6.0)\n",
      "Requirement already satisfied: ase in c:\\users\\won\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from torch-geometric) (3.20.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\won\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from torch-geometric) (2.11.2)\n",
      "Requirement already satisfied: googledrivedownloader in c:\\users\\won\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from torch-geometric) (0.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\won\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from torch-geometric) (1.5.2)\n",
      "Requirement already satisfied: requests in c:\\users\\won\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from torch-geometric) (2.24.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\won\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from torch-geometric) (2.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\won\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from torch-geometric) (4.50.2)\n",
      "Requirement already satisfied: rdflib in c:\\users\\won\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from torch-geometric) (5.0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\won\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from torch-geometric) (0.23.2)\n",
      "Requirement already satisfied: h5py in c:\\users\\won\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from torch-geometric) (2.10.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\won\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from torch-geometric) (1.18.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\won\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from numba->torch-geometric) (50.3.0.post20201006)\n",
      "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in c:\\users\\won\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from numba->torch-geometric) (0.34.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\won\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from pandas->torch-geometric) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\won\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from pandas->torch-geometric) (2020.1)\n",
      "Requirement already satisfied: future in c:\\users\\won\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from torch->torch-geometric) (0.18.2)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in c:\\users\\won\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from ase->torch-geometric) (3.3.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\won\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from jinja2->torch-geometric) (1.1.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\won\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from requests->torch-geometric) (1.25.10)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\won\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from requests->torch-geometric) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\won\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from requests->torch-geometric) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\won\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from requests->torch-geometric) (2020.6.20)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\won\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from networkx->torch-geometric) (4.4.2)\n",
      "Requirement already satisfied: six in c:\\users\\won\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from rdflib->torch-geometric) (1.15.0)\n",
      "Requirement already satisfied: isodate in c:\\users\\won\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from rdflib->torch-geometric) (0.6.0)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\won\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from rdflib->torch-geometric) (2.4.7)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\won\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from scikit-learn->torch-geometric) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\won\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from scikit-learn->torch-geometric) (0.17.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\won\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from matplotlib>=2.0.0->ase->torch-geometric) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\won\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from matplotlib>=2.0.0->ase->torch-geometric) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\won\\anaconda3\\envs\\cpu_env\\lib\\site-packages (from matplotlib>=2.0.0->ase->torch-geometric) (7.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-scatter==latest+cu102 -f https://pytorch-geometric.com/whl/torch-1.6.0.html\n",
    "!pip install torch-sparse==latest+cu102 -f https://pytorch-geometric.com/whl/torch-1.6.0.html\n",
    "!pip install torch-cluster==latest+cu102 -f https://pytorch-geometric.com/whl/torch-1.6.0.html\n",
    "!pip install torch-spline-conv==latest+cu102 -f https://pytorch-geometric.com/whl/torch-1.6.0.html\n",
    "!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set nodes, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 4], x=[3, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 두 개 씩 짝이되고, 양방향\n",
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "\n",
    "# 각 tensor에 할당되는 값\n",
    "x = torch.tensor([[-1],[0],[1]], dtype=torch.float)\n",
    "\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "data\n",
    "\n",
    "# Data에서 edge_attr도 설정할 수 있다."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 4], x=[3, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index = torch.tensor([[0, 1],\n",
    "                          [1, 0],\n",
    "                          [1, 2],\n",
    "                          [2, 1]], dtype=torch.long)\n",
    "\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "data = Data(x = x, \n",
    "           edge_index = edge_index.t().contiguous()) # 데이터 형태를 맞추기 위해 t()로 전치시킨다.\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### contiguous\n",
    "\n",
    "\n",
    "새로운 tensor를 생성하지 않고 기존의 tensor에서 메타데이터만 수정하는(메모리상에서 같은 공간 공유) narrow, view, expand, transpose 의 함수가 있다. 하지만 연산 과정에서 tensor가 메모리에 올려진 순서가 중요하다면 에러가 발생한다. 따라서 우리가 기대하는 순서로 유지하기 위해 contiguous를 사용하여 에러가 발생하는 것을 방지할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### edge_index\n",
    "\n",
    "그래프의 연결성\n",
    "\n",
    "(2,4) 크기의 행렬 -> 4개의 edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x', 'edge_index']\n",
      "tensor([[-1.],\n",
      "        [ 0.],\n",
      "        [ 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(data.keys)\n",
    "print(data['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_index found in data\n",
      "tensor([[0, 1, 1, 2],\n",
      "        [1, 0, 2, 1]])\n",
      "x found in data\n",
      "tensor([[-1.],\n",
      "        [ 0.],\n",
      "        [ 1.]])\n"
     ]
    }
   ],
   "source": [
    "for key, item in data :\n",
    "    print(\"{} found in data\".format(key))\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'edge_attr' in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node count :  3\n",
      "edge count :  4\n",
      "node features count :  1\n",
      "node isolated :  False\n",
      "itself loop :  False\n",
      "directed :  False\n"
     ]
    }
   ],
   "source": [
    "print(\"node count : \", data.num_nodes)\n",
    "print(\"edge count : \", data.num_edges)\n",
    "\n",
    "print(\"node features count : \", data.num_node_features)\n",
    "print(\"node isolated : \", data.contains_isolated_nodes())\n",
    "print(\"itself loop : \", data.contains_self_loops())\n",
    "print(\"directed : \", data.is_directed())\n",
    "\n",
    "\n",
    "# transfer data object to GPU\n",
    "device = torch.device('cuda')\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# common benchmark datasets\n",
    "\n",
    "torch_geometric.datasets 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENZYMES dataset\n",
    "\n",
    " dataset 안에 600개의 그래프가 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ENZYMES(600)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "# 그래프 데이터 세트의 non-isomorphic graph 이해 논문에서 동기를 부여한 정리 된 데이터셋\n",
    "# 일부 데이터셋은 노드 라벨이 없다. use_node_attr인수를 사용하여 추가 연속 노드 속성을 로드 /\n",
    "# torch_geometric.transforms.Constant 또는 torch_geometric.transforms.OneHotDegree 같은 변환 사용하여 합성노드기능 제공 가능\n",
    "\n",
    "dataset = TUDataset(root ='/tmp/ENZYMES', name='ENZYMES')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset len :  600\n",
      "dataset num_classes :  6\n",
      "dataset num_node_features :  3\n"
     ]
    }
   ],
   "source": [
    "print(\"dataset len : \",len(dataset)) # dataset 안에 600개의 그래프가 있음.\n",
    "print(\"dataset num_classes : \", dataset.num_classes)\n",
    "print(\"dataset num_node_features : \", dataset.num_node_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "# class 종류 : 6개\n",
    "# 어떤것이 있는지 살펴보자\n",
    "\n",
    "tmp1 = []\n",
    "for i in range(600) : \n",
    "    tmp1.append(dataset[i].y.item())\n",
    "    \n",
    "print(tmp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 168], x=[37, 3], y=[1])\n",
      "directed :  False\n"
     ]
    }
   ],
   "source": [
    "data = dataset[0]\n",
    "print(data) # edge_index=[2, 168] 인 경우에 총 84개의 edge, 37개의 node, 3개의 node features, 1개의 graph level target\n",
    "\n",
    "print(\"directed : \", data.is_directed()) # 방향성 x\n",
    "\n",
    "\n",
    "# train, test set indexing으로 분리\n",
    "train_dataset = dataset[:540] # 540개 # 9 : 1 의 비율\n",
    "test_dataset = dataset[540:] # 60개\n",
    "\n",
    "# shuffle 진행\n",
    "#dataset = dataset.shuffle()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cora dataset\n",
    "\n",
    "dataset 전체가 하나의 그래프\n",
    "\n",
    "총 1443개의 노드특성, 클래스 수는 7개(그래프가 하나이므로 target이 노드임을 알 수 있음)\n",
    "\n",
    "\n",
    "주로 (semi-supervised) graph node classification 데이터셋으로 사용\n",
    "\n",
    "\n",
    "하나의 논문은 다른 논문들을 인용할 수 있는데, 이를 연결구조로 표현한 것이 Citation Network\n",
    "\n",
    "    - 각 논문이 노드, 인용 관계가 엣지\n",
    "    - 논문의 특정 단어 1433개로 단어 사전 생성 후 -> 논문마다 단어의 등장여부를 feature vector로 생성 -> 노드의 특징\n",
    "    - 논문 내 등장한 단어들과 인용 관계만으로 어떤 종류의 논문인지 맞히는 task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset len :  1\n",
      "dataset num_classes :  7\n",
      "dataset num_node_features :  1433\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root = '/tmp/Cora', name='Cora')\n",
    "print(\"dataset len : \",len(dataset)) # dataset 안에 1개의 그래프가 있음.\n",
    "print(\"dataset num_classes : \", dataset.num_classes)\n",
    "print(\"dataset num_node_features : \", dataset.num_node_features) # node feature가 1433개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_train = []\n",
    "tmp_test = []\n",
    "tmp_val = []\n",
    "\n",
    "cnt = 0\n",
    "for i in data.train_mask :\n",
    "    tmp_train.append(i.sum().item())\n",
    "    \n",
    "for i in data.test_mask :\n",
    "    tmp_test.append(i.sum().item())\n",
    "    \n",
    "for i in data.test_mask :\n",
    "    tmp_val.append(i.sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp = pd.concat([pd.DataFrame(tmp_train), pd.DataFrame(tmp_test), pd.DataFrame(tmp_val)], axis=1)\n",
    "tmp.columns=[\"train\", 'test', 'val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 10556], test_mask=[2708], train_mask=[2708], val_mask=[2708], x=[2708, 1433], y=[2708])\n",
      "directed :  False\n",
      "140\n",
      "500\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "data = dataset[0] # 노드 하나\n",
    "print(data)\n",
    "\n",
    "print(\"directed : \", data.is_directed()) # 방향성 x\n",
    "\n",
    "print(data.train_mask.sum().item()) # 학습하기 위해 사용하는 노드들\n",
    "print(data.val_mask.sum().item()) # 검증하기 위해 사용하는 노드들\n",
    "\n",
    "print(data.test_mask.sum().item()) # 테스트하기 위해 사용하는 노드들 #  검증(500) + 테스트(500) = 테스트(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Mini-batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "pytorch geometric은 sparse block diagonal adjacency matrices를 통해 미니배치 형태로 만들고, 병렬화하여 수행한다.\n",
    "\n",
    "기존 torch에서는 torch.utils.data.DataLoader를 통해 배치 단위로 데이터를 처리하였다.\n",
    "\n",
    "torch_geometric에서는 torch_geometric.data.DataLoader 를 통해 그래프 단위 데이터를 처리하게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(batch=[1029], edge_index=[2, 3996], x=[1029, 21], y=[32])\n",
      "32\n",
      "Batch(batch=[990], edge_index=[2, 3780], x=[990, 21], y=[32])\n",
      "32\n",
      "Batch(batch=[1078], edge_index=[2, 4168], x=[1078, 21], y=[32])\n",
      "32\n",
      "Batch(batch=[944], edge_index=[2, 3654], x=[944, 21], y=[32])\n",
      "32\n",
      "Batch(batch=[1094], edge_index=[2, 4068], x=[1094, 21], y=[32])\n",
      "32\n",
      "Batch(batch=[979], edge_index=[2, 3820], x=[979, 21], y=[32])\n",
      "32\n",
      "Batch(batch=[1047], edge_index=[2, 4172], x=[1047, 21], y=[32])\n",
      "32\n",
      "Batch(batch=[1062], edge_index=[2, 4230], x=[1062, 21], y=[32])\n",
      "32\n",
      "Batch(batch=[1094], edge_index=[2, 3880], x=[1094, 21], y=[32])\n",
      "32\n",
      "Batch(batch=[1016], edge_index=[2, 3902], x=[1016, 21], y=[32])\n",
      "32\n",
      "Batch(batch=[1084], edge_index=[2, 4154], x=[1084, 21], y=[32])\n",
      "32\n",
      "Batch(batch=[1067], edge_index=[2, 3654], x=[1067, 21], y=[32])\n",
      "32\n",
      "Batch(batch=[1025], edge_index=[2, 3938], x=[1025, 21], y=[32])\n",
      "32\n",
      "Batch(batch=[1069], edge_index=[2, 4100], x=[1069, 21], y=[32])\n",
      "32\n",
      "Batch(batch=[838], edge_index=[2, 3258], x=[838, 21], y=[32])\n",
      "32\n",
      "Batch(batch=[1184], edge_index=[2, 4332], x=[1184, 21], y=[32])\n",
      "32\n",
      "Batch(batch=[984], edge_index=[2, 3786], x=[984, 21], y=[32])\n",
      "32\n",
      "Batch(batch=[1257], edge_index=[2, 4658], x=[1257, 21], y=[32])\n",
      "32\n",
      "Batch(batch=[739], edge_index=[2, 3014], x=[739, 21], y=[24])\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES', use_node_attr = True)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True) #  y값을 32개 가지는 배치 단위로 데이터를 로더한다.\n",
    "\n",
    "for batch in loader :\n",
    "    print(batch)\n",
    "    print(batch.num_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(batch=[1054], edge_index=[2, 3922], x=[1054, 21], y=[32])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "Batch(batch=[1018], edge_index=[2, 3992], x=[1018, 21], y=[32])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "Batch(batch=[1212], edge_index=[2, 4470], x=[1212, 21], y=[32])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "Batch(batch=[1226], edge_index=[2, 4126], x=[1226, 21], y=[32])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "Batch(batch=[973], edge_index=[2, 3822], x=[973, 21], y=[32])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "Batch(batch=[992], edge_index=[2, 3888], x=[992, 21], y=[32])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "Batch(batch=[962], edge_index=[2, 3778], x=[962, 21], y=[32])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "Batch(batch=[1140], edge_index=[2, 4200], x=[1140, 21], y=[32])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "Batch(batch=[1013], edge_index=[2, 3804], x=[1013, 21], y=[32])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "Batch(batch=[938], edge_index=[2, 3662], x=[938, 21], y=[32])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "Batch(batch=[947], edge_index=[2, 3682], x=[947, 21], y=[32])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "Batch(batch=[1084], edge_index=[2, 4186], x=[1084, 21], y=[32])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "Batch(batch=[1122], edge_index=[2, 4384], x=[1122, 21], y=[32])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "Batch(batch=[1094], edge_index=[2, 4008], x=[1094, 21], y=[32])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "Batch(batch=[1079], edge_index=[2, 4076], x=[1079, 21], y=[32])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "Batch(batch=[1036], edge_index=[2, 4082], x=[1036, 21], y=[32])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "Batch(batch=[916], edge_index=[2, 3546], x=[916, 21], y=[32])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "Batch(batch=[1049], edge_index=[2, 4050], x=[1049, 21], y=[32])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "Batch(batch=[725], edge_index=[2, 2886], x=[725, 21], y=[24])\n",
      "24\n",
      "torch.Size([24, 21])\n"
     ]
    }
   ],
   "source": [
    "from torch_scatter import scatter_mean\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES', use_node_attr=True)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "for data in loader:\n",
    "    print(data)\n",
    "    print(data.num_graphs)\n",
    "\n",
    "    x = scatter_mean(data.x, data.batch, dim=0)\n",
    "    print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data Transforms\n",
    "\n",
    "ShapeNet dataset 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://shapenet.cs.stanford.edu/media/shapenetcore_partanno_segmentation_benchmark_v0_normal.zip\n"
     ]
    },
    {
     "ename": "URLError",
     "evalue": "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1123)>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSSLCertVerificationError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1349\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0m\u001b[0;32m   1351\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\http\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1254\u001b[0m         \u001b[1;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1255\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1300\u001b[0m             \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1301\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\http\\client.py\u001b[0m in \u001b[0;36mendheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1249\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1250\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1009\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1010\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1011\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\http\\client.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    949\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    951\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\http\\client.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1424\u001b[1;33m             self.sock = self._context.wrap_socket(self.sock,\n\u001b[0m\u001b[0;32m   1425\u001b[0m                                                   server_hostname=server_hostname)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[1;31m# ctx._wrap_socket()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m         return self.sslsocket_class._create(\n\u001b[0m\u001b[0;32m    501\u001b[0m             \u001b[0msock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\ssl.py\u001b[0m in \u001b[0;36m_create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1039\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1308\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1309\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1310\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSSLCertVerificationError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1123)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-65b24fc02bb0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mShapeNet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mShapeNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'/tmp/ShapeNet'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Airplane'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\torch_geometric\\datasets\\shapenet.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, categories, include_normals, split, transform, pre_transform, pre_filter)\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategory\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategory_ids\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcategory\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcategories\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategories\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcategories\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         super(ShapeNet, self).__init__(root, transform, pre_transform,\n\u001b[0m\u001b[0;32m    104\u001b[0m                                        pre_filter)\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, transform, pre_transform, pre_filter)\u001b[0m\n\u001b[0;32m     51\u001b[0m     def __init__(self, root=None, transform=None, pre_transform=None,\n\u001b[0;32m     52\u001b[0m                  pre_filter=None):\n\u001b[1;32m---> 53\u001b[1;33m         super(InMemoryDataset, self).__init__(root, transform, pre_transform,\n\u001b[0m\u001b[0;32m     54\u001b[0m                                               pre_filter)\n\u001b[0;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\torch_geometric\\data\\dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, transform, pre_transform, pre_filter)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'download'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_download\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'process'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\torch_geometric\\data\\dataset.py\u001b[0m in \u001b[0;36m_download\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\torch_geometric\\datasets\\shapenet.py\u001b[0m in \u001b[0;36mdownload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdownload_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m         \u001b[0mextract_zip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\torch_geometric\\data\\download.py\u001b[0m in \u001b[0;36mdownload_url\u001b[1;34m(url, folder, log)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'urllib.Request'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;31m# post-process response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0m\u001b[0;32m    543\u001b[0m                                   '_open', req)\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1392\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1393\u001b[1;33m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0m\u001b[0;32m   1394\u001b[0m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0;32m   1395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1351\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0;32m   1352\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# timeout error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1353\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1354\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1355\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1123)>"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import ShapeNet\n",
    "\n",
    "dataset = ShapeNet(root='/tmp/ShapeNet', categories=['Airplane'])\n",
    "dataset[0]\n",
    "\n",
    "# url이 현재 오픈되지 않아서 진행 불가 \n",
    "# https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html#learning-methods-on-graphs 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Learning Methods on Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "\n",
    "class Net(torch.nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "        \n",
    "    def forward(self, data) :\n",
    "        \n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  0 loss :  1.9462432861328125\n",
      "epoch :  100 loss :  0.04740346223115921\n",
      "epoch :  200 loss :  0.03155552223324776\n",
      "epoch :  300 loss :  0.024845609441399574\n",
      "epoch :  400 loss :  0.016182707622647285\n",
      "epoch :  500 loss :  0.01877479813992977\n",
      "epoch :  600 loss :  0.025309834629297256\n",
      "epoch :  700 loss :  0.016346612945199013\n",
      "epoch :  800 loss :  0.017613442614674568\n",
      "epoch :  900 loss :  0.014527320861816406\n",
      "epoch :  1000 loss :  0.01724926009774208\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = Net().to(device)\n",
    "data = dataset[0].to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1000+1) :\n",
    "    optimizer.zero_grad() # 초기화\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask]) # train index의 prediction, 실제값의 loss 계산\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0 :\n",
    "        print('epoch : ', epoch,'loss : ', loss.item())\n",
    "        # batch는 좀 불안정하게 loss가 감소한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 80.4000 %\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "_, pred = model(data).max(dim=1)\n",
    "correct = float(pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "acc = correct / data.test_mask.sum().item()\n",
    "\n",
    "print('Accuracy : {:.4f} %'.format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "어떻게 활용해볼 수 있을까 ?\n",
    "\n",
    "* node : 확진자\n",
    "* edge : 접촉 관계\n",
    "* node_features : 사람의 특징(성별, 연령 등)\n",
    "* edge_features : 접촉 시 상황(접촉 장소 특징, 접촉 시 주변 사람 수, 몇차 감염 등)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Creating Message Passing Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* (j , i) : source_to_target\n",
    "\n",
    "* (i, j) : target_to_source\n",
    "\n",
    "tensors -> propagate\n",
    "\n",
    "---\n",
    "\n",
    "neighboring node features are first transformed by a weight matrix Θ\n",
    " \n",
    "normalized by their degree & finally summed up\n",
    " \n",
    "Add self-loops to the adjacency matrix.\n",
    "\n",
    "Linearly transform node feature matrix.\n",
    "\n",
    "Compute normalization coefficients.\n",
    "\n",
    "Normalize node features in ϕ.\n",
    "\n",
    "Sum up neighboring node features (\"add\" aggregation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## GCNConv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "GCN : Graphic Convolutional Network\n",
    "\n",
    "graph convolution을 이용하여 그래프에 포함된 node, 그래프 자체를 벡터 형태의 데이터로 변환한다.\n",
    "\n",
    "기본적인 GCN에서는 node의 feature만을 고려한다(edge feature 고려 x)\n",
    "\n",
    "G = (A, X) = (A의 인접행렬, node feature matrix) = ( N X N , N x d )\n",
    "\n",
    "* N : node 수\n",
    "* d : node feature vector의 차원\n",
    "\n",
    "H = σ(AXW)\n",
    "* W : weight matrix\n",
    "\n",
    "학습 과정이 진행되면서 weight matrix를 조정하게 된다. σ는 sigmoid, ReLU와 같이 비선형적 출력을 생성하기 위한 non-linear activation function이다.\n",
    "\n",
    "한계점 :\n",
    "\n",
    "1 ) A에는 neighbor node와의 연결만 표현되어 있기 때문에 graph convolution 과정에서 해당 node 자체에 대한 정보는 latent feature vector 생성 시 고려되지 않는다.\n",
    "\n",
    "2 ) 일반적으로 A는 정규화되어있지 않으므로 feature vector와 A를 곱할 경우 feature vector의 크기가 불안정하게 변할 수 있다.\n",
    "\n",
    "=> 이를 해결하기 위해 \"self-loop\"추가하여 정규화 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class GCNConv(MessagePassing) :\n",
    "    def __init__(self, in_channels, out_channels) :\n",
    "        super(GCNConv, self).__init__(aggr='add') # Step5 :\"add\" aggregation \n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "        \n",
    "    def forward(self, x, edge_index) :\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index shape : [ 2, E ]\n",
    "        \n",
    "        print('x shape : ', x.shape) \n",
    "        print('edge_index shape : ', edge_index.shape)\n",
    "        \n",
    "        # Step1 : Add self-loops to the adjacency matrix\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        # edge_index : [0, 1], [2, 1] 양방향\n",
    "        # x : -1, 0, 1  # x.size : 3\n",
    "        \n",
    "        \n",
    "        # Step2 : Linearly transform node feature matrix\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        \n",
    "        # Step3 : Compute normalization\n",
    "        row, col = edge_index # [ 2, E ]\n",
    "        print('row :{}, col : {}'.format(row, col))\n",
    "        \n",
    "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "        print(deg)\n",
    "        \n",
    "        deg_inv_sqrt = deg.pow(-0.5) # sqrt\n",
    "        \n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col] # 행렬계산\n",
    "\n",
    "        # Step4 : start propagating messages\n",
    "        return self.propagate(edge_index, x=x, norm=norm)\n",
    "    \n",
    "    def message(self, x_j, norm) : # normalize the neighboring node features\n",
    "        # x_j shape : [ E, out_channels ]\n",
    "        \n",
    "        # Step4 : Normalize node features\n",
    "        return norm.view(-1, 1) * x_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape :  torch.Size([3, 2])\n",
      "edge_index shape :  torch.Size([2, 4])\n",
      "row :tensor([0, 1, 1, 2, 0, 1, 2]), col : tensor([1, 0, 2, 1, 0, 1, 2])\n",
      "tensor([2., 3., 2.])\n",
      "tensor([[-2.2648,  0.3196, -2.2564,  1.0869,  2.5566, -1.5219,  3.1983, -1.7067,\n",
      "         -3.3021, -1.4961],\n",
      "        [-2.8370, -0.0917, -3.4935,  1.2399,  3.7804, -1.6944,  4.1488, -2.6119,\n",
      "         -4.4382, -2.4921],\n",
      "        [-2.2171, -0.4646, -3.2627,  0.8719,  3.4157, -1.1549,  3.3559, -2.4197,\n",
      "         -3.7093, -2.4409]], grad_fn=<ScatterAddBackward>)\n"
     ]
    }
   ],
   "source": [
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "\n",
    "\n",
    "x = torch.tensor([[-1, 4],\n",
    "                  [0, 5],\n",
    "                  [1, 6]], dtype=torch.float)\n",
    "\n",
    "# in_channel size = x.shape[-1] 과 맞춰주어야함.\n",
    "conv = GCNConv(x.shape[-1],10)\n",
    "x = conv(x, edge_index)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## EdgeConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU\n",
    "from torch_geometric.nn import MessagePassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# transform both the target node features x_i, relative source node features x_i - x_j for each edge\n",
    "class EdgeConv(MessagePassing) : \n",
    "    def __init__(self, in_channels, out_channels) :\n",
    "        super(EdgeConv, self).__init__(aggr=\"max\") # max aggregation\n",
    "        \n",
    "        # MLP\n",
    "        # in_channels에 2 곱하는 이유 ? node 연결 정보가 반복해서 들어오기 때문?\n",
    "        self.mlp = Seq(Linear(2 * in_channels, out_channels),\n",
    "                      ReLU(),\n",
    "                      Linear(out_channels, out_channels))\n",
    "        \n",
    "    def forward(self, x, edge_index) :\n",
    "        # x shape : [N, in_channels]\n",
    "        # edge_index shape : [2, E]\n",
    "        \n",
    "        return self.propagate(edge_index, x=x)\n",
    "    \n",
    "    def message(self, x_i, x_j) :\n",
    "        # x_i shape : [E, in_channels]\n",
    "        # x_j shape : [E, in_channels]\n",
    "        print(x_i)\n",
    "        print(x_j)\n",
    "        \n",
    "        # 두 텐서 연결하기, dim=몇번째 차원을 늘릴것인가 ? \n",
    "        # 2 x 2 -> dim=0 일 때 4 x 2, dim=1 일 때 2 x 4\n",
    "        tmp = torch.cat([x_i, x_j - x_i], dim=1) # tmp shape : [E, 2*in_channels]\n",
    "        return self.mlp(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import knn_graph\n",
    "\n",
    "class DynamicEdgeConv(EdgeConv) :\n",
    "    def __init__(self, in_channels, out_channels, k=6) :\n",
    "        super(DynamicEdgeConv, self).__init__(in_channels, out_channels)\n",
    "        self.k = k\n",
    "        \n",
    "    def forward(self, x, batch=None) :\n",
    "        edge_index = knn_graph(x, self.k, batch, loop=False, flow=self.flow)\n",
    "        return super(DynamicEdgeConv, self).forward(x, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-63aa8ba83408>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mconv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDynamicEdgeConv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'batch' is not defined"
     ]
    }
   ],
   "source": [
    "conv = DynamicEdgeConv(3, 128, k=6)\n",
    "x = conv(x, batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Creating Own Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Creating \"In Memory Datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class MyOwnDataset(InMemoryDataset) :\n",
    "    def __init__(self, root, transform=None, pre_transform=None) :\n",
    "        super(MyOwnDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        \n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self) :\n",
    "        return ['some_file_1', 'some_file2', ... ]\n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self) :\n",
    "        return ['data.pt']\n",
    "    \n",
    "    # def download(self) :\n",
    "        # download to 'self.raw_dir'\n",
    "        \n",
    "    def process(self) :\n",
    "        # read data into huge 'data' list\n",
    "        data_list = [...]\n",
    "        \n",
    "        if self.pre_filter is not None :\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "        \n",
    "        if self.pre_transform is not None :\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "            \n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_path[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Creating \"Larger\" Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class MyOwnDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(MyOwnDataset, self).__init__(root, transform, pre_transform)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['some_file_1', 'some_file_2', ...]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data_1.pt', 'data_2.pt', ...]\n",
    "\n",
    "    def download(self):\n",
    "        # Download to `self.raw_dir`.\n",
    "\n",
    "    def process(self):\n",
    "        i = 0\n",
    "        for raw_path in self.raw_paths:\n",
    "            # Read data from `raw_path`.\n",
    "            data = Data(...)\n",
    "\n",
    "            if self.pre_filter is not None and not self.pre_filter(data):\n",
    "                continue\n",
    "\n",
    "            if self.pre_transform is not None:\n",
    "                data = self.pre_transform(data)\n",
    "\n",
    "            torch.save(data, osp.join(self.processed_dir, 'data_{}.pt'.format(i)))\n",
    "            i += 1\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = torch.load(osp.join(self.processed_dir, 'data_{}.pt'.format(idx)))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Advanced Mini-Batching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Pairs of Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class PairData(Data) :\n",
    "    def __init__(self, edge_index_s, x_s, edge_index_t, x_t) :\n",
    "        self.edge_indexx_s = edge_index_s\n",
    "        self.x_s = x_s\n",
    "        self.edge_index_t = edge_index_t\n",
    "        self.x_t = x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def __inc__(self, key, value) :\n",
    "    if key == 'edge_index_s' :\n",
    "        return self.x_s.size(0)\n",
    "    if key == 'edge_index_t' :\n",
    "        return self.x_t.size(0)\n",
    "    else :\n",
    "        return super(PairData, self).__inc__(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PairData' object has no attribute 'face'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-0b68645df19a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mdata_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\torch_geometric\\data\\dataloader.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\torch_geometric\\data\\dataloader.py\u001b[0m in \u001b[0;36mcollate\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0melem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mBatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_data_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfollow_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\torch_geometric\\data\\batch.py\u001b[0m in \u001b[0;36mfrom_data_list\u001b[1;34m(data_list, follow_batch)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m                 \u001b[0mslices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mslices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m                 \u001b[0minc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__inc__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m                     \u001b[0minc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\torch_geometric\\data\\data.py\u001b[0m in \u001b[0;36m__inc__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[1;31m# Only `*index*` and `*face*` attributes should be cumulatively summed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[1;31m# up when creating batches.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_nodes\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'(index|face)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cpu_env\\lib\\site-packages\\torch_geometric\\data\\data.py\u001b[0m in \u001b[0;36mnum_nodes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'adj_t'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madj_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mface\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__num_nodes_warn_msg__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'face'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_num_nodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mface\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'PairData' object has no attribute 'face'"
     ]
    }
   ],
   "source": [
    "edge_index_s = torch.tensor([\n",
    "    [0, 0, 0, 0],\n",
    "    [1, 2, 3, 4],])\n",
    "\n",
    "x_s = torch.randn(5, 16) # 5 nodes\n",
    "\n",
    "\n",
    "edge_index_t = torch.tensor([\n",
    "    [0, 0, 0],\n",
    "    [1, 2, 3],\n",
    "])\n",
    "x_t = torch.randn(4, 16) # 4 nodes\n",
    "\n",
    "data = PairData(edge_index_s, x_s, edge_index_t, x_t)\n",
    "data_list = [data, data]\n",
    "loader = DataLoader(data_list, batch_size = 2)\n",
    "batch = next(iter(loader))\n",
    "\n",
    "print(batch)\n",
    "\n",
    "print(batch.edge_index_s)\n",
    "\n",
    "print(batch.edge_index_t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Bipartite Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class BipartiteData(Data) :\n",
    "    def __init__(self, edge_index, x_s, x_t) :\n",
    "        super(BipartiteData, self).__init__()\n",
    "        self.edge_index = edge_index\n",
    "        self.x_s = x_s\n",
    "        self.x_t = x_T\n",
    "        \n",
    "\n",
    "def __inc__(self, key, value) :\n",
    "    if key == 'edge_index' :\n",
    "        return torch.tensor([[self.x_s.size(0)], [self.x_t.size(0)]])\n",
    "    else :\n",
    "        return super(BipartiteData, self).__inc__(key, value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "edge_index = torch.tensor([\n",
    "    [0, 0, 1, 1],\n",
    "    [0, 1, 1, 2],\n",
    "])\n",
    "\n",
    "x_s = torch.randn(2, 16) # 2 nodes\n",
    "x_t = torch.randn(3, 16) # 3 nodes\n",
    "\n",
    "data = BipartiteData(edge_index, x_s, x_t)\n",
    "data_list = [data, data]\n",
    "loader = DataLoader(data_list, batch_size=2)\n",
    "batch = next(iter(loader))\n",
    "\n",
    "print(batch)\n",
    "print(batch.edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory-Efficient Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import MessagePassing\n",
    "\n",
    "class MyConv(MessagePassing) :\n",
    "    def __init__(self) :\n",
    "        super(MyConv, self).__init__(aggr=\"add\")\n",
    "        \n",
    "    def forward(self, x, edge_index) :\n",
    "        return self.propagate(edge_index, x=x)\n",
    "    \n",
    "    def message(self, x_i, x_j) :\n",
    "        return MLP(x_j - x_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numberof graphs : 1\n",
      "Numberof features : 34\n",
      "Numberof classes : 2\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import KarateClub\n",
    "\n",
    "dataset = KarateClub()\n",
    "print(f'Numberof graphs : {len(dataset)}')\n",
    "print(f'Numberof features : {dataset.num_features}')\n",
    "print(f'Numberof classes : {dataset.num_classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 156], x=[34, 34], y=[34])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0] # graph 수 = 1\n",
    "\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 156], x=[34, 34], y=[34])\n",
      "==============================================================\n",
      "Number of nodes: 34\n",
      "Number of edges: 156\n",
      "Average node degree: 4.59\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Data' object has no attribute 'train_mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-0000d9fb57c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Number of edges: {data.num_edges}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Average node degree: {data.num_edges / data.num_nodes:.2f}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Number of training nodes: {data.train_mask.sum()}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Contains isolated nodes: {data.contains_isolated_nodes()}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Data' object has no attribute 'train_mask'"
     ]
    }
   ],
   "source": [
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "print(data)\n",
    "print('==============================================================')\n",
    "\n",
    "# Gather some statistics about the graph.\n",
    "print(f'Number of nodes: {data.num_nodes}') # 34\n",
    "print(f'Number of edges: {data.num_edges}') # 156\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}') # 156/34\n",
    "\n",
    "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
    "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
    "print(f'Contains isolated nodes: {data.contains_isolated_nodes()}')\n",
    "print(f'Contains self-loops: {data.contains_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "272px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
