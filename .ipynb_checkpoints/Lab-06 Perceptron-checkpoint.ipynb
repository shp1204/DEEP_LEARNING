{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Linear Perceptron\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "\n",
    "_ http://www.bristolwatch.com/pport/python_examples.html _\n",
    "\n",
    "## 1.1 AND\n",
    "\n",
    "\n",
    "## 1.2 OR\n",
    "\n",
    "\n",
    "## 1.3 XOR ( X ) => Multi lyaer Perceptron 으로 해결(민스키) \n",
    "## => 학습이 불가능 => Backpropagation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 xor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# for reproducibility\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn layers\n",
    "linear = torch.nn.Linear(2, 1, bias=True)\n",
    "sigmoid = torch.nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = torch.nn.Sequential(linear, sigmoid).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "criterion = torch.nn.BCELoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6931471824645996\n",
      "1000 0.6931471824645996\n",
      "2000 0.6931471824645996\n",
      "3000 0.6931471824645996\n",
      "4000 0.6931471824645996\n",
      "5000 0.6931471824645996\n",
      "6000 0.6931471824645996\n",
      "7000 0.6931471824645996\n",
      "8000 0.6931471824645996\n",
      "9000 0.6931471824645996\n",
      "10000 0.6931471824645996\n"
     ]
    }
   ],
   "source": [
    "for step in range(10001):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "\n",
    "    # cost/loss function\n",
    "    cost = criterion(hypothesis, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 1000 == 0:\n",
    "        print(step, cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hypothesis:  [[0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]] \n",
      "Correct:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] \n",
      "Accuracy:  50.0 %\n"
     ]
    }
   ],
   "source": [
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "with torch.no_grad():\n",
    "    hypothesis = model(X)\n",
    "    predicted = (hypothesis > 0.5).float()\n",
    "    accuracy = (predicted == Y).float().mean()\n",
    "    print('\\nHypothesis: ', hypothesis.detach().cpu().numpy(), '\\nCorrect: ', predicted.detach().cpu().numpy(), '\\nAccuracy: ', accuracy.item() * 100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 xor_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)\n",
    "\n",
    "# nn layers\n",
    "# multi layers\n",
    "linear1 = torch.nn.Linear(2, 2, bias=True) \n",
    "linear2 = torch.nn.Linear(2, 1, bias=True)\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "# model\n",
    "model = torch.nn.Sequential(linear1, sigmoid, linear2, sigmoid).to(device)\n",
    "\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "criterion = torch.nn.BCELoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1)  # modified learning rate from 0.1 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.34716302156448364\n",
      "1000 0.3471029996871948\n",
      "2000 0.34705421328544617\n",
      "3000 0.34701329469680786\n",
      "4000 0.34697872400283813\n",
      "5000 0.3469492793083191\n",
      "6000 0.3469237983226776\n",
      "7000 0.3469012677669525\n",
      "8000 0.3468814790248871\n",
      "9000 0.3468639552593231\n",
      "10000 0.3468482494354248\n"
     ]
    }
   ],
   "source": [
    "for step in range(10001):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "\n",
    "    # cost/loss function\n",
    "    cost = criterion(hypothesis, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 1000 == 0:\n",
    "        print(step, cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hypothesis:  [[2.7531455e-04]\n",
      " [4.9987873e-01]\n",
      " [9.9970007e-01]\n",
      " [5.0014031e-01]] \n",
      "Correct:  [[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]] \n",
      "Accuracy:  50.0 %\n"
     ]
    }
   ],
   "source": [
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "with torch.no_grad():\n",
    "    hypothesis = model(X)\n",
    "    predicted = (hypothesis > 0.5).float()\n",
    "    accuracy = (predicted == Y).float().mean()\n",
    "    print('\\nHypothesis: ', hypothesis.detach().cpu().numpy(), '\\nCorrect: ', predicted.detach().cpu().numpy(), '\\nAccuracy: ', accuracy.item() * 100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 xor-nn-wide-deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn layers\n",
    "linear1 = torch.nn.Linear(2, 10, bias=True)\n",
    "linear2 = torch.nn.Linear(10, 10, bias=True)\n",
    "linear3 = torch.nn.Linear(10, 10, bias=True)\n",
    "linear4 = torch.nn.Linear(10, 1, bias=True)\n",
    "sigmoid = torch.nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = torch.nn.Sequential(linear1, sigmoid, linear2, sigmoid, linear3, sigmoid, linear4, sigmoid).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "criterion = torch.nn.BCELoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1)  # modified learning rate from 0.1 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.00011170558718731627\n",
      "1000 9.523803601041436e-05\n",
      "2000 8.288382377941161e-05\n",
      "3000 7.324200123548508e-05\n",
      "4000 6.562694761669263e-05\n",
      "5000 5.936805246165022e-05\n",
      "6000 5.415234045358375e-05\n",
      "7000 4.975625779479742e-05\n",
      "8000 4.6045686758589e-05\n",
      "9000 4.281198198441416e-05\n",
      "10000 3.998064494226128e-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for step in range(10001):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "\n",
    "    # cost/loss function\n",
    "    cost = criterion(hypothesis, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 1000 == 0:\n",
    "        print(step, cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hypothesis:  [[3.0086994e-05]\n",
      " [9.9996173e-01]\n",
      " [9.9995995e-01]\n",
      " [5.1474111e-05]] \n",
      "Correct:  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy:  100.0 %\n"
     ]
    }
   ],
   "source": [
    "# True if hypothesis>0.5 else False\n",
    "with torch.no_grad():\n",
    "    hypothesis = model(X)\n",
    "    predicted = (hypothesis > 0.5).float()\n",
    "    accuracy = (predicted == Y).float().mean()\n",
    "    print('\\nHypothesis: ', hypothesis.detach().cpu().numpy(), '\\nCorrect: ', predicted.detach().cpu().numpy(), '\\nAccuracy: ', accuracy.item() * 100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.695397138595581\n",
      "1000 0.6953632831573486\n",
      "2000 0.695330023765564\n",
      "3000 0.6952971816062927\n",
      "4000 0.6952646374702454\n",
      "5000 0.6952325701713562\n",
      "6000 0.6952009797096252\n",
      "7000 0.6951702237129211\n",
      "8000 0.6951398849487305\n",
      "9000 0.6951098442077637\n",
      "10000 0.695080041885376\n"
     ]
    }
   ],
   "source": [
    "# nn layers\n",
    "w1 = torch.Tensor(2, 2).to(device)\n",
    "b1 = torch.Tensor(2).to(device)\n",
    "w2 = torch.Tensor(2, 1).to(device)\n",
    "b2 = torch.Tensor(1).to(device)\n",
    "\n",
    "def sigmoid(x) :\n",
    "    return 1./ ( 1.0 + torch.exp(-x))\n",
    "\n",
    "# sigmoid 미분한 뒤 함수\n",
    "def sigmoid_prime(x) :\n",
    "    return sigmoid(x) * ( 1- sigmoid(x))\n",
    "\n",
    "learning_rate = 0.00001\n",
    "\n",
    "for step in range(10001) :\n",
    "    # forward\n",
    "    l1 = torch.add(torch.matmul(X, w1), b1)\n",
    "    a1 = sigmoid(l1)\n",
    "    l2 = torch.add(torch.matmul(a1, w2), b2)\n",
    "    Y_pred = sigmoid(l2)\n",
    "    \n",
    "    # binary sigmoid 함수\n",
    "    cost = -torch.mean(Y * torch.log(Y_pred) + (1 - Y) * torch.log(1 - Y_pred) )\n",
    "    \n",
    "    # Back prop (chain rule)\n",
    "    # Loss derivative\n",
    "    d_Y_pred = (Y_pred - Y) / (Y_pred * (1.0 - Y_pred) + 1e-7)\n",
    "    \n",
    "    # layer 2\n",
    "    d_l2 = d_Y_pred * sigmoid_prime(l2)\n",
    "    d_b2 = d_l2\n",
    "    d_w2 = torch.matmul(torch.transpose(a1, 0, 1), d_b2)\n",
    "    \n",
    "    # layer 1\n",
    "    d_a1 = torch.matmul(d_b2, torch.transpose(w2, 0, 1))\n",
    "    d_l1 = d_a1 * sigmoid_prime(l1)\n",
    "    d_b1 = d_l1\n",
    "    d_w1 = torch.matmul(torch.transpose(X, 0, 1), d_b1)\n",
    "    \n",
    "    # weight update\n",
    "    w1 = w1 - learning_rate * d_w1\n",
    "    b1 = b1 - learning_rate * torch.mean(d_b1, 0)\n",
    "    w2 = w2 - learning_rate * d_w2\n",
    "    b2 = b2 - learning_rate * torch.mean(d_b2, 0)\n",
    "    \n",
    "    if step % 1000 == 0 :\n",
    "        print(step, cost.item())\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
